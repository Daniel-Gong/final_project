{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/1cb97fa63a3629c6d892af4f76fcc4ad8191837c/build.log`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "using Flux\n",
        "using Hopfields\n",
        "using HDF5\n",
        "using PyCall\n",
        "\n",
        "ENV[\"PYTHON\"] = \"/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\"\n",
        "Pkg.build(\"PyCall\")\n",
        "println(PyCall.python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "@pyimport tensorflow as tf\n",
        "@pyimport numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PyObject <__main__.ContinuousHopfield object at 0x2de9180a0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "class ContinuousHopfield:\n",
        "    def __init__(self, pat_size, beta=100, do_normalization=True):\n",
        "        self.size = pat_size  # size of individual pattern\n",
        "        self.beta = beta\n",
        "        print(self.beta)\n",
        "        self.max_norm = np.sqrt(self.size)\n",
        "        if do_normalization:\n",
        "            self.softmax = self.softmax_normalized\n",
        "            self.energy = self.energy_normalized\n",
        "        else:\n",
        "            self.softmax = self.softmax_unnormalized\n",
        "            self.energy = self.energy_unnormalized\n",
        "\n",
        "        return\n",
        "\n",
        "    def learn(self, patterns):\n",
        "        # expects patterns as numpy arrays and stores them col-wise in pattern matrix \n",
        "        self.num_pat = len(patterns)\n",
        "        assert (all(type(x) is np.ndarray for x in patterns)), 'not all input patterns are numpy arrays'\n",
        "        assert (all(len(x.shape) == 2 for x in patterns)), 'not all input patterns have dimension 2'\n",
        "        assert (all(1 == x.shape[1] for x in patterns)), 'not all input patterns have shape (-1,1) '\n",
        "        self.patterns = np.array(patterns).squeeze(axis=-1).T  # save patterns col-wise\n",
        "        # without squeeze axis would result in problem with one pattern\n",
        "        # return -1*np.sum(np.exp([(self.patterns[:,ii].T @pattern)/self.max_norm for ii in range(self.patterns.shape[1])]))\n",
        "        self.M = max(np.linalg.norm(vec) for vec in patterns)  # maximal norm of actually stored patterns\n",
        "        return\n",
        "\n",
        "    def retrieve(self, partial_pattern, max_iter=np.inf, thresh=0.5):\n",
        "        # partial patterns have to be provided with None/0 at empty spots\n",
        "        if partial_pattern.size != self.size:\n",
        "            raise ValueError(\"Input pattern %r does not match state size: %d vs %d\"\n",
        "                             % (partial_pattern, len(partial_pattern), self.size))\n",
        "\n",
        "        if None in partial_pattern:\n",
        "            raise NotImplementedError(\"None elements not supported\")\n",
        "\n",
        "        assert type(partial_pattern) == np.ndarray, 'test pattern was not numpy array'\n",
        "        assert len(partial_pattern.shape) == 2 and 1 == partial_pattern.shape[\n",
        "            1], 'test pattern with shape %r is not a col-vector' % (partial_pattern.shape,)\n",
        "\n",
        "        pat_old = partial_pattern.copy()\n",
        "        iters = 0\n",
        "\n",
        "        while iters < max_iter:\n",
        "            pat_new = self.patterns @ self.softmax(self.beta * self.patterns.T @ pat_old)\n",
        "\n",
        "            if np.count_nonzero(pat_old != pat_new) <= thresh:  # converged\n",
        "                break\n",
        "            else:\n",
        "                pat_old = pat_new\n",
        "            iters += 1\n",
        "\n",
        "        return pat_new\n",
        "\n",
        "    def softmax_unnormalized(z):\n",
        "        return softmax(z)  # Scipy's softmax is numerically stable\n",
        "\n",
        "    def softmax_normalized(self, z):\n",
        "        return softmax(z / self.max_norm)\n",
        "\n",
        "    @staticmethod\n",
        "    def _lse(z, beta):\n",
        "        return 1 / beta * np.log(np.sum(np.exp(beta * z)))\n",
        "\n",
        "    def energy_unnormalized(self, pattern):\n",
        "        return -1 * self._lse(self.patterns.T @ pattern, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_normalized(self, pattern):\n",
        "        # normalize dot product of patterns by 1/sqrt(pattern_size)\n",
        "        return -1 * self._lse((self.patterns.T @ pattern) / self.max_norm, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_landscape(self):\n",
        "        for pat in product([1, -1], repeat=self.size):\n",
        "            pat = np.array(pat)\n",
        "            print(\"energy(%r)=%.3f\" % (pat, self.energy(pat)))\n",
        "\"\"\"\n",
        "\n",
        "# Create an instance of the Python class in Julia\n",
        "pat_size = (64,64,3)\n",
        "continuous_hopfield = py\"ContinuousHopfield\"(pat_size, beta=100, do_normalization=true)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia 1.9.3",
      "language": "julia",
      "name": "julia-1.9"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
