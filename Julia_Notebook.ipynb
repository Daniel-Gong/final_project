{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/1cb97fa63a3629c6d892af4f76fcc4ad8191837c/build.log`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mlibevent_jll\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mPMIx_jll\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDistributions → DistributionsChainRulesCoreExt\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenSSL\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mprrte_jll\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mOpenMPI_jll\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m  ✓ \u001b[39m\u001b[90mHDF5_jll\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mHTTP\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mDataDeps\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m  ✓ \u001b[39mHDF5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mH5Zblosc\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMAT\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39mJLD\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnitful\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnitful → ConstructionBaseUnitfulExt\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mPeriodicTable\u001b[39m\n",
            "\u001b[32m  ✓ \u001b[39m\u001b[90mUnitfulAtomic\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mAtomsBase\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mChemfiles\u001b[39m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39m\u001b[90mMLDatasets\u001b[39m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m  ✓ \u001b[39mGenTF\n",
            "  21 dependencies successfully precompiled in 30 seconds. 366 already precompiled.\n",
            "  \u001b[33m2\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n",
            "  \u001b[33m1\u001b[39m dependency had warnings during precompilation:\u001b[33m\n",
            "┌ \u001b[39mJLD [4138dd39-2aa7-5051-a626-17a0bb65d9c8]\u001b[33m\n",
            "│  \u001b[39mWARNING: could not import HDF5.exists into JLD\u001b[33m\n",
            "└  \u001b[39m\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "using Flux\n",
        "using Hopfields\n",
        "using HDF5\n",
        "using PyCall\n",
        "\n",
        "ENV[\"PYTHON\"] = \"/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\"\n",
        "Pkg.build(\"PyCall\")\n",
        "println(PyCall.python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "function load_shapes3d_dataset(file_path, type =\"train\")\n",
        "    # randomly sample 10 integers from 1 to 480000\n",
        "    random_idx = rand(1:480000, 10000)\n",
        "    if type == \"test\"\n",
        "        random_idx = rand(1:480000, 1000)\n",
        "    end\n",
        "    dataset = h5open(file_path, \"r\") do file\n",
        "        read(file[\"images\"])[:, :, :, random_idx]\n",
        "    end\n",
        "    dataset = permutedims(dataset, [4, 3, 2, 1])\n",
        "    println(\"Dataset shape: \", size(dataset))\n",
        "    # Convert and reshape the dataset to a list of 1d vectors\n",
        "    converted_dataset = ((dataset ./ 255) .* 2) .- 1\n",
        "    converted_dataset = [reshape(converted_dataset[i,:,:,:], (64*64*3,1)) for i in 1:size(converted_dataset)[1]]\n",
        "    println(\"Converted dataset shape: \", size(converted_dataset))\n",
        "    return dataset, converted_dataset\n",
        "end\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (100, 64, 64, 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted dataset shape: (100,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([0x99 0x99 … 0xff 0xff; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xf9 0xec; 0x99 0x99 … 0x38 0x37;;; 0x99 0x99 … 0xff 0xff; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xf6 0xe9; 0x99 0x99 … 0x38 0x35;;; 0x99 0x99 … 0xff 0xff; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xf3 0xf0; 0x99 0x99 … 0x36 0x34;;; … ;;; 0x99 0x99 … 0xd8 0xd6; 0x99 0x99 … 0xec 0xe4; … ; 0x99 0x99 … 0xbd 0xbd; 0x99 0x99 … 0x2c 0x2c;;; 0x99 0x99 … 0xd8 0xcd; 0x99 0x99 … 0xeb 0xe5; … ; 0x99 0x99 … 0xbc 0xbc; 0x99 0x99 … 0x2c 0x2b;;; 0x99 0x99 … 0xd8 0xcd; 0x99 0x99 … 0xe9 0xe3; … ; 0x99 0x99 … 0xbb 0xbb; 0x99 0x99 … 0x2c 0x2a;;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xbf 0xbd; … ; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xff 0xff;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xbe 0xbc; … ; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xff 0xff;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xbd 0xbb; … ; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xff 0xff;;; … ;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0x8f 0x89; … ; 0xe2 0xe2 … 0xec 0xec; 0xe2 0xe2 … 0xdf 0xdd;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0x8e 0x8b; … ; 0xe2 0xe2 … 0xea 0xea; 0xe2 0xe2 … 0xde 0xdb;;; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0x8d 0x89; … ; 0xe2 0xe2 … 0xe9 0xe9; 0xe2 0xe2 … 0xdc 0xd7;;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00;;; … ;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00;;; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x00 0x00; 0xf9 0xf9 … 0x00 0x00], [[0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; 0.7411764705882353; 0.780392156862745;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; 0.050980392156862786; 0.07450980392156858;;], [0.19999999999999996; 0.19999999999999996; … ; 0.6627450980392158; 0.7019607843137254;;], [0.19999999999999996; 0.19999999999999996; … ; 0.050980392156862786; 0.08235294117647052;;], [0.19999999999999996; 0.19999999999999996; … ; 0.6627450980392158; 0.7019607843137254;;], [0.19999999999999996; 0.19999999999999996; … ; 0.6941176470588235; 0.6235294117647059;;]  …  [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; 0.6549019607843136; 0.6941176470588235;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -0.2705882352941177; -0.24705882352941178;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "train_data,converted_dataset = load_shapes3d_dataset(\"3dshapes.h5\", \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (10, 64, 64, 3)\n",
            "Converted dataset shape: (10,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xfb 0xff; 0x99 0x99 … 0x00 0x00;;; 0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xf6 0xf8; 0x99 0x99 … 0x00 0x00;;; 0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xff 0xff; … ; 0x99 0x99 … 0xfa 0xf3; 0x99 0x99 … 0x00 0x00;;; … ;;; 0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xe2 0xde; … ; 0x99 0x99 … 0xdc 0xdb; 0x99 0x99 … 0x00 0x00;;; 0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xe7 0xe0; … ; 0x99 0x99 … 0xd7 0xdb; 0x99 0x99 … 0x00 0x00;;; 0x99 0x99 … 0x00 0x00; 0x99 0x99 … 0xe5 0xe4; … ; 0x99 0x99 … 0xd4 0xd9; 0x99 0x99 … 0x00 0x00;;;; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xb7 0xb2; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xff 0xff;;; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xb6 0xb3; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xff 0xff;;; 0xe2 0xe2 … 0xff 0xff; 0xe2 0xe2 … 0xb5 0xb3; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xff 0xff;;; … ;;; 0xe2 0xe2 … 0xe2 0xde; 0xe2 0xe2 … 0x88 0x86; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xe3 0xe7;;; 0xe2 0xe2 … 0xe7 0xe0; 0xe2 0xe2 … 0x8b 0x87; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xe2 0xe5;;; 0xe2 0xe2 … 0xe5 0xe4; 0xe2 0xe2 … 0x8a 0x8a; … ; 0xe2 0xe2 … 0x00 0x00; 0xe2 0xe2 … 0xde 0xe3;;;; 0xf9 0xf9 … 0x7a 0x77; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x98 0x9b; 0xf9 0xf9 … 0xff 0xff;;; 0xf9 0xf9 … 0x7a 0x77; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x93 0x95; 0xf9 0xf9 … 0xff 0xff;;; 0xf9 0xf9 … 0x79 0x77; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x96 0x92; 0xf9 0xf9 … 0xff 0xff;;; … ;;; 0xf9 0xf9 … 0x5b 0x59; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x84 0x84; 0xf9 0xf9 … 0xe3 0xe7;;; 0xf9 0xf9 … 0x5d 0x5a; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x81 0x84; 0xf9 0xf9 … 0xe2 0xe5;;; 0xf9 0xf9 … 0x5c 0x5c; 0xf9 0xf9 … 0x00 0x00; … ; 0xf9 0xf9 … 0x80 0x83; 0xf9 0xf9 … 0xde 0xe3], [[0.19999999999999996; 0.19999999999999996; … ; -0.2784313725490196; -0.2784313725490196;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -0.30980392156862746; -0.34901960784313724;;], [0.19999999999999996; 0.19999999999999996; … ; 0.050980392156862786; 0.05882352941176472;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; 0.6941176470588235; 0.6235294117647059;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; -1.0; -1.0;;], [0.19999999999999996; 0.19999999999999996; … ; 0.0039215686274509665; 0.027450980392156765;;], [0.19999999999999996; 0.19999999999999996; … ; 0.7411764705882353; 0.780392156862745;;]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_data,_ = load_shapes3d_dataset(\"3dshapes.h5\", \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhZJREFUeAHtwYFuWkEUQ8Fjyf//y7dspDQUIUjSBT8Sz3hmqBxTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJTFMlSGqSgPi9hjqM8Si6koi2XYQ+w0/ATiumExFWXeiJ2GPcROw2OJ64ZLYhGLqSjzAGKPYSfxWMN14hZTUebAxE7DY4nvMBVlfg1xRKaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShzYMMe4rhMRZkDEz+fqShzMMNjiWMxFWUOYFjEMwyPIr7DVJTZZPhfw8OIZTgRzzDcIj6YivKwh9hj+CJxy7AMfw3PIO4bFlNRFnsMTyfuEx+GReJBZng33CcWU1Eenk7ihhk+aVjEZ4llhv3EicRdM7wbFlNRRuLJhjdDhMQyLGKj4cxwlcS/TEWZGXYSd4k34sOwiJMZXpQ4I64azgxgKspI1NOIMwJMRZmKMhVlKspUlKkoU1GmokxFmdclfgBTUaaiTEWZijIVZSrKVJQ5kOH3MRVlDkEsw4nEyQx3DYv4NLEMizgGU1HmQMQynEhcmOFrxKVhEUdiKsocjliGCxJfM1wSx2MqyhyUuDR8jXgFpqLMyxA/kakoU1GmokxFmYoyFWUqylSUqShTUaai/gBTjUYK6pyHhwAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhZJREFUeAHtwYFuWkEUQ8Fjyf//y7dspDQUIUjSBT8Sz3hmqBxTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJTFMlSGqSgPi9hjqM8Si6koi2XYQ+w0/ATiumExFWXeiJ2GPcROw2OJ64ZLYhGLqSjzAGKPYSfxWMN14hZTUebAxE7DY4nvMBVlfg1xRKaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShzYMMe4rhMRZkDEz+fqShzMMNjiWMxFWUOYFjEMwyPIr7DVJTZZPhfw8OIZTgRzzDcIj6YivKwh9hj+CJxy7AMfw3PIO4bFlNRFnsMTyfuEx+GReJBZng33CcWU1Eenk7ihhk+aVjEZ4llhv3EicRdM7wbFlNRRuLJhjdDhMQyLGKj4cxwlcS/TEWZGXYSd4k34sOwiJMZXpQ4I64azgxgKspI1NOIMwJMRZmKMhVlKspUlKkoU1GmokxFmdclfgBTUaaiTEWZijIVZSrKVJQ5kOH3MRVlDkEsw4nEyQx3DYv4NLEMizgGU1HmQMQynEhcmOFrxKVhEUdiKsocjliGCxJfM1wSx2MqyhyUuDR8jXgFpqLMyxA/kakoU1GmokxFmYoyFWUqylSUqShTUaai/gBTjUYK6pyHhwAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(255.0,0.0,0.0)      …  RGB{Float64}(220.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(222.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(226.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(218.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(218.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)      …  RGB{Float64}(222.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(228.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(233.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(233.0,0.0,0.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAnRJREFUeAHtwQFqZEkQQ8En0P2vrCUxpoZmodnZ8VfZkxFOwuoxq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqLH6+cC+zqhx+PnEvs6osfr5wL7OqzF9A3MusKrOqzKoyq8qsKvOthPfEd2JWlblYeCXeC6/EvcyqMpcJh3gV3hOvwiHuYlaVuUYY4gi/I7wSRxjiFmZVmQuEIUb488IhRhiiz6wqUxWGGOEJYYgRhmgyq8qUhCFGeFoYYoQhOsyqMo8LR2gKRxjiaWZVmQeF24UhnmNWlXmcGOEuYoSnmVVlHhGOcKNwhCGeYFaVeZAY4V5ihOeYVWUWYoQGs6rMFwtHuF04whBfy6wq8wgxwg3EEf6NGOEJZlWZv4i4j1lVZlWZVWWuJl6FV+I7M6vKPCL8KeLrheeYVWW+mBhhiBE+iBFuIkYY4glmVZkriL+VWVXmQeFX4QhDPCcMMcKn8DSzqswjxAhDjPBBjNARPokRhniOWVXmQWKEX4UhRhjia4UhRgAxwhBPM6vKXCEMMcIQf14YYoRPocmsKvM4McIQI3wIQ4xwiN8XDjHCJzHCEB1mVZkSMcIQI3wIQxzhEO+FQxzhkxhhiCazqkyVGGGII4RD/DfiCJ/EEYboM6vKXECMcIgRPoT/R4xwiFuYVWWuIY4wxKvwnngVhriRWVXmSuIIh3gvHGKIe5lVZa4njvCe+E7MqjLfivhpzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsqn8AZvRt9JRjX10AAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAnRJREFUeAHtwQFqZEkQQ8En0P2vrCUxpoZmodnZ8VfZkxFOwuoxq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqLH6+cC+zqhx+PnEvs6osfr5wL7OqzF9A3MusKrOqzKoyq8qsKvOthPfEd2JWlblYeCXeC6/EvcyqMpcJh3gV3hOvwiHuYlaVuUYY4gi/I7wSRxjiFmZVmQuEIUb488IhRhiiz6wqUxWGGOEJYYgRhmgyq8qUhCFGeFoYYoQhOsyqMo8LR2gKRxjiaWZVmQeF24UhnmNWlXmcGOEuYoSnmVVlHhGOcKNwhCGeYFaVeZAY4V5ihOeYVWUWYoQGs6rMFwtHuF04whBfy6wq8wgxwg3EEf6NGOEJZlWZv4i4j1lVZlWZVWWuJl6FV+I7M6vKPCL8KeLrheeYVWW+mBhhiBE+iBFuIkYY4glmVZkriL+VWVXmQeFX4QhDPCcMMcKn8DSzqswjxAhDjPBBjNARPokRhniOWVXmQWKEX4UhRhjia4UhRgAxwhBPM6vKXCEMMcIQf14YYoRPocmsKvM4McIQI3wIQ4xwiN8XDjHCJzHCEB1mVZkSMcIQI3wIQxzhEO+FQxzhkxhhiCazqkyVGGGII4RD/DfiCJ/EEYboM6vKXECMcIgRPoT/R4xwiFuYVWWuIY4wxKvwnngVhriRWVXmSuIIh3gvHGKIe5lVZa4njvCe+E7MqjLfivhpzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsKrOqzKoyq8qsqn8AZvRt9JRjX10AAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,126.0,255.0)    …  RGB{Float64}(0.0,89.0,222.0)\n",
              " RGB{Float64}(0.0,125.0,255.0)       RGB{Float64}(0.0,87.0,219.0)\n",
              " RGB{Float64}(0.0,126.0,255.0)       RGB{Float64}(0.0,89.0,221.0)\n",
              " RGB{Float64}(0.0,121.0,255.0)       RGB{Float64}(0.0,90.0,224.0)\n",
              " RGB{Float64}(0.0,123.0,255.0)       RGB{Float64}(0.0,87.0,218.0)\n",
              " RGB{Float64}(0.0,122.0,255.0)    …  RGB{Float64}(0.0,90.0,223.0)\n",
              " RGB{Float64}(0.0,117.0,255.0)       RGB{Float64}(0.0,90.0,225.0)\n",
              " RGB{Float64}(0.0,117.0,255.0)       RGB{Float64}(0.0,89.0,221.0)\n",
              " RGB{Float64}(0.0,118.0,255.0)       RGB{Float64}(0.0,88.0,219.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAepJREFUeAHtwVFSYgEQBMGaiLr/lWd9/rDB6gqINGpnurtUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlNSdDLeQipIfZEhabiEV5fC25RZD0pI03EIqSl4t54ZbLEnD9yMVJa+Gc8t1hsNQ15GKkncM9QhSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRErUkDXlSUfJwy8nw20lFycMNJ0vSkCcVJQ+xHIbDcrnhUsv1lsNwWA7Do0lFScoMH1suNVxll+cgFSUpu3xohgvt8j1JRck/lq+y/GWGF7u8mOGTZvjYchhe7PIcpKJcTobDcH/LYTgsz2U5WT5ruI5UlMPJ8rWW5zJ8leVSUlEu7xg+tnzWELR8leFSUlEy/M/yP8N3NbxtuYvlUlJRspwM54afbDk3PJhUlAy/13B/y1WkoqTua7iKVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSU/DrLM5GKkpjl3HKL4TrDYXkOUlESMxyWw3IY7ml52/JMpKIkZjm33NPwtuWZSEXJj7V8B1JRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUX8A+OQ9+/pr4cAAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAepJREFUeAHtwVFSYgEQBMGaiLr/lWd9/rDB6gqINGpnurtUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlNSdDLeQipIfZEhabiEV5fC25RZD0pI03EIqSl4t54ZbLEnD9yMVJa+Gc8t1hsNQ15GKkncM9QhSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRErUkDXlSUfJwy8nw20lFycMNJ0vSkCcVJQ+xHIbDcrnhUsv1lsNwWA7Do0lFScoMH1suNVxll+cgFSUpu3xohgvt8j1JRck/lq+y/GWGF7u8mOGTZvjYchhe7PIcpKJcTobDcH/LYTgsz2U5WT5ruI5UlMPJ8rWW5zJ8leVSUlEu7xg+tnzWELR8leFSUlEy/M/yP8N3NbxtuYvlUlJRspwM54afbDk3PJhUlAy/13B/y1WkoqTua7iKVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSU/DrLM5GKkpjl3HKL4TrDYXkOUlESMxyWw3IY7ml52/JMpKIkZjm33NPwtuWZSEXJj7V8B1JRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUX8A+OQ9+/pr4cAAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(244.0,0.0,255.0)    …  RGB{Float64}(176.0,0.0,221.0)\n",
              " RGB{Float64}(245.0,0.0,255.0)       RGB{Float64}(174.0,0.0,218.0)\n",
              " RGB{Float64}(235.0,0.0,255.0)       RGB{Float64}(171.0,0.0,215.0)\n",
              " RGB{Float64}(236.0,0.0,255.0)       RGB{Float64}(176.0,0.0,221.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)       RGB{Float64}(177.0,0.0,222.0)\n",
              " RGB{Float64}(224.0,0.0,255.0)    …  RGB{Float64}(172.0,0.0,215.0)\n",
              " RGB{Float64}(223.0,0.0,255.0)       RGB{Float64}(173.0,0.0,217.0)\n",
              " RGB{Float64}(223.0,0.0,255.0)       RGB{Float64}(176.0,0.0,220.0)\n",
              " RGB{Float64}(218.0,0.0,255.0)       RGB{Float64}(172.0,0.0,215.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAW9JREFUeAHtwTFuW0EAxUAuwPtfeRO5MRC4SCV+WG/Gey/TkUnJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRS8pkOL5ecTEo+weHb5VFkUvI7HF4uP7u8HB5IJiXPd/hfh/91eQiZlJxD4/LX5d0O/7qEZFJyLx/u8OVQkEnJObzP5eXw1708xOXLpSCTkjl8ObxcXg7vIpOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZMSLu92eaLLt8u7yKSEQ+PyLIeCTEq4zMulIJOSScmkZFIyKakcXi4fTiYlz3d5OfxKMilpHX52+Xb4xWRS8kyHDyGTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpP4A3CEe/A1slMYAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAW9JREFUeAHtwTFuW0EAxUAuwPtfeRO5MRC4SCV+WG/Gey/TkUnJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRS8pkOL5ecTEo+weHb5VFkUvI7HF4uP7u8HB5IJiXPd/hfh/91eQiZlJxD4/LX5d0O/7qEZFJyLx/u8OVQkEnJObzP5eXw1708xOXLpSCTkjl8ObxcXg7vIpOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZMSLu92eaLLt8u7yKSEQ+PyLIeCTEq4zMulIJOSScmkZFIyKakcXi4fTiYlz3d5OfxKMilpHX52+Xb4xWRS8kyHDyGTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpP4A3CEe/A1slMYAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(250.0,0.0,255.0)    …  RGB{Float64}(177.0,0.0,222.0)\n",
              " RGB{Float64}(251.0,0.0,255.0)       RGB{Float64}(174.0,0.0,219.0)\n",
              " RGB{Float64}(252.0,0.0,255.0)       RGB{Float64}(176.0,0.0,221.0)\n",
              " RGB{Float64}(243.0,0.0,255.0)       RGB{Float64}(179.0,0.0,224.0)\n",
              " RGB{Float64}(244.0,0.0,255.0)       RGB{Float64}(174.0,0.0,218.0)\n",
              " RGB{Float64}(243.0,0.0,255.0)    …  RGB{Float64}(178.0,0.0,223.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)       RGB{Float64}(180.0,0.0,225.0)\n",
              " RGB{Float64}(232.0,0.0,255.0)       RGB{Float64}(177.0,0.0,221.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)       RGB{Float64}(175.0,0.0,219.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAi5JREFUeAHtwVGS21YUQ8GDKux/y9fDHzNWXiiGpREoD7o9M1SOqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKiLWhvpf4YirKDGviiqEeibXhi6koI9aGK8QVw99ArA1r4oupKPNfxBXDFeKK4d3EkWFNHDAVZV5LXDFcIa4YnhNrwxFxgakocwfiiuEK8dywJl7OVJT5XOKK4TnxNqaizE8jbsVUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZk7GDbiBzIVZe5A/FimokzWkCTiTEWZ+qfhiHg5U1HmPYbXEK837MRZwxFxkqkoM7yGOCLWhoxhIx4NZ4n/Z1gyFWXEawwfTjw3/DacJTZiyVSUGd5IPBruYnhOnDX8NhwwFWX+IL7XcF9iM2zE2nCWOMdUlEHshu8lNsNGbIZPIs4azjEVZRh2ol5DnGMqyiAqx1SUqShTUaaiTEWZijIVZSrKVJSpKFNR5icb4kxFmQCxGd5gOCI2Q5CpKBMjHg0XDGtiI9aGzRBnKsrcwrARu2Fp2ImNWBtOEI/Ee5mKMrcgNsNObIYHYjecII4MO5FgKsrciNgNG7Ebvgz/Io4MR0SaqShzU2Iz7MTacETcm6koc2tiN6yJT2YqynwM8TcyFWUqylSUqShTUaaiTEWZijIV9Qtth0cHzsX7fQAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAi5JREFUeAHtwVGS21YUQ8GDKux/y9fDHzNWXiiGpREoD7o9M1SOqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKiLWhvpf4YirKDGviiqEeibXhi6koI9aGK8QVw99ArA1r4oupKPNfxBXDFeKK4d3EkWFNHDAVZV5LXDFcIa4YnhNrwxFxgakocwfiiuEK8dywJl7OVJT5XOKK4TnxNqaizE8jbsVUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZk7GDbiBzIVZe5A/FimokzWkCTiTEWZ+qfhiHg5U1HmPYbXEK837MRZwxFxkqkoM7yGOCLWhoxhIx4NZ4n/Z1gyFWXEawwfTjw3/DacJTZiyVSUGd5IPBruYnhOnDX8NhwwFWX+IL7XcF9iM2zE2nCWOMdUlEHshu8lNsNGbIZPIs4azjEVZRh2ol5DnGMqyiAqx1SUqShTUaaiTEWZijIVZSrKVJSpKFNR5icb4kxFmQCxGd5gOCI2Q5CpKBMjHg0XDGtiI9aGzRBnKsrcwrARu2Fp2ImNWBtOEI/Ee5mKMrcgNsNObIYHYjecII4MO5FgKsrciNgNG7Ebvgz/Io4MR0SaqShzU2Iz7MTacETcm6koc2tiN6yJT2YqynwM8TcyFWUqylSUqShTUaaiTEWZijIV9Qtth0cHzsX7fQAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(255.0,194.0,0.0)    …  RGB{Float64}(224.0,135.0,0.0)\n",
              " RGB{Float64}(255.0,194.0,0.0)       RGB{Float64}(221.0,133.0,0.0)\n",
              " RGB{Float64}(255.0,199.0,0.0)       RGB{Float64}(222.0,133.0,0.0)\n",
              " RGB{Float64}(255.0,199.0,0.0)       RGB{Float64}(223.0,134.0,0.0)\n",
              " RGB{Float64}(255.0,192.0,0.0)       RGB{Float64}(234.0,142.0,0.0)\n",
              " RGB{Float64}(255.0,196.0,0.0)    …  RGB{Float64}(237.0,143.0,0.0)\n",
              " RGB{Float64}(255.0,193.0,0.0)       RGB{Float64}(236.0,142.0,0.0)\n",
              " RGB{Float64}(255.0,186.0,0.0)       RGB{Float64}(231.0,139.0,0.0)\n",
              " RGB{Float64}(255.0,191.0,0.0)       RGB{Float64}(240.0,145.0,0.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAkJJREFUeAHtwYFqIwcQRME30P//yx0GYzYnNj7JkdUr01WyTeWIihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEvU0w+NERYlfZUgyjxMVJRjOme8YkkzS8DhRUQJzbvgOkzS8G1FRguGc+Y6hHiEqSvynoX6eqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSrwxcxjek6go8TbMV8yt4R2IihKXZr7PHIarEhUl/mAyhlvmmcwarkdUlMAchgzzCuZ1hvuIihIMB5MxHMzPGl7B3EdUlMCcGf7OPIt5HfMKw31ERWn4ijk3rOH/MmtY5nWGc+ZZzH1ERYkvDa9gXmNYBsy54dVERYkLGJb5CcMyfxqWWcPzmXuJihK/1pAz3EtUlLi0YZl7DcucM9cjKkpczrDMYXjMcG5Y5kpERYnLMQezhu8zB3M9oqJE1LDMGpb5MCzzHMMyMCyzhjxRUeIyzL+ZNSyzhseYNSzzyVyLqChxAcMya1jmg1nDMreGg7k1LPNpWGYNVyEqSlzGsMwalvlg1vCV4Zb5NCyzhmsRFSUuZlhmDQdjHjEczBquSFSUuKRhmcNwMOeGgzkM1yUqSlzYcDCH4Zw5DO9BVJR4E8MtcxjW8H5ERYm3NfwGoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqKh/ANSCUwCVqWzoAAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAkJJREFUeAHtwYFqIwcQRME30P//yx0GYzYnNj7JkdUr01WyTeWIihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEvU0w+NERYlfZUgyjxMVJRjOme8YkkzS8DhRUQJzbvgOkzS8G1FRguGc+Y6hHiEqSvynoX6eqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSrwxcxjek6go8TbMV8yt4R2IihKXZr7PHIarEhUl/mAyhlvmmcwarkdUlMAchgzzCuZ1hvuIihIMB5MxHMzPGl7B3EdUlMCcGf7OPIt5HfMKw31ERWn4ijk3rOH/MmtY5nWGc+ZZzH1ERYkvDa9gXmNYBsy54dVERYkLGJb5CcMyfxqWWcPzmXuJihK/1pAz3EtUlLi0YZl7DcucM9cjKkpczrDMYXjMcG5Y5kpERYnLMQezhu8zB3M9oqJE1LDMGpb5MCzzHMMyMCyzhjxRUeIyzL+ZNSyzhseYNSzzyVyLqChxAcMya1jmg1nDMreGg7k1LPNpWGYNVyEqSlzGsMwalvlg1vCV4Zb5NCyzhmsRFSUuZlhmDQdjHjEczBquSFSUuKRhmcNwMOeGgzkM1yUqSlzYcDCH4Zw5DO9BVJR4E8MtcxjW8H5ERYm3NfwGoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqKh/ANSCUwCVqWzoAAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,122.0,255.0)    …  RGB{Float64}(0.0,89.0,221.0)\n",
              " RGB{Float64}(0.0,123.0,255.0)       RGB{Float64}(0.0,88.0,218.0)\n",
              " RGB{Float64}(0.0,118.0,255.0)       RGB{Float64}(0.0,87.0,215.0)\n",
              " RGB{Float64}(0.0,118.0,255.0)       RGB{Float64}(0.0,89.0,221.0)\n",
              " RGB{Float64}(0.0,117.0,255.0)       RGB{Float64}(0.0,89.0,222.0)\n",
              " RGB{Float64}(0.0,112.0,255.0)    …  RGB{Float64}(0.0,87.0,215.0)\n",
              " RGB{Float64}(0.0,112.0,255.0)       RGB{Float64}(0.0,87.0,217.0)\n",
              " RGB{Float64}(0.0,112.0,255.0)       RGB{Float64}(0.0,88.0,220.0)\n",
              " RGB{Float64}(0.0,109.0,255.0)       RGB{Float64}(0.0,87.0,215.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAm1JREFUeAHtwYFOIwkQQ8Fnyf//y31qnVbDwgAhyuIJuMozQ+WYijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqIM4txQ/5YAU1GG4Zy4x1CviXMDmIoyiHPDPcQ9hp9AnBvOCTAVZd4l7jHcQxyG6xIfGc6J95mKMg8m7jFcizg3fER8nakocwliDd9HfGQ4Jx7NVJS5hOG7DR8R38VUlPl1xJWYijI/hHhOpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFMMSySYijK/1HAQh+Ej4tFMRZkHG56DOAwHcavhVuJ9pqIMw2OIJe4xfIfhc8OtxK2G95mKMojHGJ6DWAOINSzxueGl4VbifaaiDMN3EeeGqxgOYg1LLHGr4aXhfaaizAvi3xquTrwmzg3nxBK3MhVl8dpwD/E5cRiWWMPzEV8znDMVZd4QP9uQIM6ZijK/wrDEGv4mkkxFmRCxhrfEGh5v+NuwRJKpKHMBYg1viUcSawCxhjxTUSZKrOGlYYk1LHG/YYk1/DEskWcqylyGWMNbwxJfM5wRa7gKU1HmAsQalljDcBBreE0choNYYg1rALGGJa7CVJS5DLGGJdbwv2GJj4jXhj/EGpa4FlNR5mLEGpY4DMNXiMOwxBWZijKXJNZwEIfhnDgMB3FdpqLMhYnDcBDnhoN4DqaizJMQrw0HscTzMRVlnpb4CUxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNR/wH2aVwIwRbwLgAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAm1JREFUeAHtwYFOIwkQQ8Fnyf//y31qnVbDwgAhyuIJuMozQ+WYijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqIM4txQ/5YAU1GG4Zy4x1CviXMDmIoyiHPDPcQ9hp9AnBvOCTAVZd4l7jHcQxyG6xIfGc6J95mKMg8m7jFcizg3fER8nakocwliDd9HfGQ4Jx7NVJS5hOG7DR8R38VUlPl1xJWYijI/hHhOpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFMMSySYijK/1HAQh+Ej4tFMRZkHG56DOAwHcavhVuJ9pqIMw2OIJe4xfIfhc8OtxK2G95mKMojHGJ6DWAOINSzxueGl4VbifaaiDMN3EeeGqxgOYg1LLHGr4aXhfaaizAvi3xquTrwmzg3nxBK3MhVl8dpwD/E5cRiWWMPzEV8znDMVZd4QP9uQIM6ZijK/wrDEGv4mkkxFmRCxhrfEGh5v+NuwRJKpKHMBYg1viUcSawCxhjxTUSZKrOGlYYk1LHG/YYk1/DEskWcqylyGWMNbwxJfM5wRa7gKU1HmAsQalljDcBBreE0choNYYg1rALGGJa7CVJS5DLGGJdbwv2GJj4jXhj/EGpa4FlNR5mLEGpY4DMNXiMOwxBWZijKXJNZwEIfhnDgMB3FdpqLMhYnDcBDnhoN4DqaizJMQrw0HscTzMRVlnpb4CUxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNR/wH2aVwIwRbwLgAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,129.0,255.0)    …  RGB{Float64}(0.0,91.0,224.0)\n",
              " RGB{Float64}(0.0,129.0,255.0)       RGB{Float64}(0.0,89.0,221.0)\n",
              " RGB{Float64}(0.0,132.0,255.0)       RGB{Float64}(0.0,89.0,222.0)\n",
              " RGB{Float64}(0.0,132.0,255.0)       RGB{Float64}(0.0,90.0,223.0)\n",
              " RGB{Float64}(0.0,128.0,255.0)       RGB{Float64}(0.0,95.0,234.0)\n",
              " RGB{Float64}(0.0,130.0,255.0)    …  RGB{Float64}(0.0,96.0,237.0)\n",
              " RGB{Float64}(0.0,128.0,255.0)       RGB{Float64}(0.0,95.0,236.0)\n",
              " RGB{Float64}(0.0,124.0,255.0)       RGB{Float64}(0.0,93.0,231.0)\n",
              " RGB{Float64}(0.0,127.0,255.0)       RGB{Float64}(0.0,96.0,240.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAARxJREFUeAHtwQENAzEAxLBUCn/KHYxUv7O99zIdmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlDzt8n0zKw7su3yeT8vKuw/fJpDxMSSYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZQ84NI49GRSkrr8O5mUpA7/TiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSib1A9McCQCSy8zaAAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAARxJREFUeAHtwQENAzEAxLBUCn/KHYxUv7O99zIdmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlDzt8n0zKw7su3yeT8vKuw/fJpDxMSSYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZQ84NI49GRSkrr8O5mUpA7/TiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSib1A9McCQCSy8zaAAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,255.0,255.0)    …  RGB{Float64}(0.0,216.0,216.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,218.0,218.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,223.0,223.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,217.0,217.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,221.0,221.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)    …  RGB{Float64}(0.0,222.0,222.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,216.0,216.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,218.0,218.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,222.0,222.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAitJREFUeAHtwQFqHFEQQ8HXoPtfWZleiCdZAo5JFv01qpJtKkdUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUhmUqQ1SUzBrem3lXoqI0LPMehj8b3pWoKPEwnMis4WY+N9zMGpY5kagocSSzhmW+xtyGZdZwIlFR4jBmDcv8K7OGZdZwFlFR4hhmDcv8T+Zm1nAKUVHiAOZmXmVY5iyiosQxhmVexaxhmTXkiYoSxzAvMyxzIFFRIsqsYZkXmOFiHgyYNZxCVJR4RzN8yuZi1rDME7OGJFFR4rua4WIOJypKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKixPc2Zg2nEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUiBqWeRmzxvzOrCFPVJQ4xrDMwwwXm/9jWAaGZU4hKkqcyebD8DB8jbkMy+ZUoqLEAYZl1rDMwwwXm8vwNWbNsAwMy6zhFKKixDGGZX5hc5nhYvNheBhu5mLWDJcZLjY/mTWcRVSUONiwbPNhhj8bLsOy+WlY5lyiosRhhptZwzIPNn9nWGYN5xIVJQ42LLOGZ+Y2PDNrOJ2oKHG8YZlnw808G96DqCjxJoZn5ja8K1FR4m0N34GoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUq6gcii1z6pPXZ0wAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAitJREFUeAHtwQFqHFEQQ8HXoPtfWZleiCdZAo5JFv01qpJtKkdUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUhmUqQ1SUzBrem3lXoqI0LPMehj8b3pWoKPEwnMis4WY+N9zMGpY5kagocSSzhmW+xtyGZdZwIlFR4jBmDcv8K7OGZdZwFlFR4hhmDcv8T+Zm1nAKUVHiAOZmXmVY5iyiosQxhmVexaxhmTXkiYoSxzAvMyxzIFFRIsqsYZkXmOFiHgyYNZxCVJR4RzN8yuZi1rDME7OGJFFR4rua4WIOJypKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKixPc2Zg2nEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUiBqWeRmzxvzOrCFPVJQ4xrDMwwwXm/9jWAaGZU4hKkqcyebD8DB8jbkMy+ZUoqLEAYZl1rDMwwwXm8vwNWbNsAwMy6zhFKKixDGGZX5hc5nhYvNheBhu5mLWDJcZLjY/mTWcRVSUONiwbPNhhj8bLsOy+WlY5lyiosRhhptZwzIPNn9nWGYN5xIVJQ42LLOGZ+Y2PDNrOJ2oKHG8YZlnw808G96DqCjxJoZn5ja8K1FR4m0N34GoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUq6gcii1z6pPXZ0wAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,127.0,255.0)    …  RGB{Float64}(0.0,87.0,219.0)\n",
              " RGB{Float64}(0.0,124.0,255.0)       RGB{Float64}(0.0,88.0,219.0)\n",
              " RGB{Float64}(0.0,126.0,255.0)       RGB{Float64}(0.0,89.0,223.0)\n",
              " RGB{Float64}(0.0,126.0,255.0)       RGB{Float64}(0.0,87.0,218.0)\n",
              " RGB{Float64}(0.0,121.0,255.0)       RGB{Float64}(0.0,90.0,223.0)\n",
              " RGB{Float64}(0.0,122.0,255.0)    …  RGB{Float64}(0.0,90.0,226.0)\n",
              " RGB{Float64}(0.0,122.0,255.0)       RGB{Float64}(0.0,88.0,220.0)\n",
              " RGB{Float64}(0.0,118.0,255.0)       RGB{Float64}(0.0,90.0,222.0)\n",
              " RGB{Float64}(0.0,111.0,255.0)       RGB{Float64}(0.0,91.0,227.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAlRJREFUeAHtwYFOXFcAQ8Fjyf//y+67qcJSsirKBvDSesZJmB4zVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlNlpspMlZkqM1VmqsxUmakyU2WmykyVmSozVWaqzFSZqTJTZabKTJWZKjNVBvGIMB/BTJUhPEJ8rvD/YKbKIB4Rvivxp8IjxD1mqsyDxMcIhzjCVwh/Sjwi3GOmyjyF8NXEEQ7xe8IjxD1mqkyZOMJnEjfhb+EQjxAfx0yVqQmH+HzhEM/ITJX5hsQjwiGO8Fo4RIOZKjNVZqrMVJmpMlNlpspMlZkqM1VmqsxUmakyU2WmykyVmSozVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlNlpsrMnxPvC3eZqTJfT7wVOsTHCO8Td5mpMuKrhWcRPoZ4X7jLTJUJX00c4RBH6BBHOMTnEneZqTLifyU8FzNVpkZ8lXCII/xK9JipMi3iSDjEEd4jHhd+kXCR6DFTZZ6BOMJFHOEQH0kc4QeJS0KbmSpTJi7hRTjEEQ7xuHCII7wSfhBtZqpMlzgSLhKXhH8Kh/g94Sa8InEJh6gzU2WegcQl4SIBSfhJHOEtcRNuxCGO8IrEJeEi8RzMVJnnIXFJuEhcEiAc4t+It8IrEpeEi8QzMVNlno3EJeEi8VMSfovEi4SLxPMxU2Wek8QlHOKQeBF+CDfiIm7CjcSzMlNlnpm4SXghcYg3El5IfAdmqsx3IfFGuBGHxHdjpsp8X+I/wEyVmSozVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlP1FykJYQ+7D9AbAAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAlRJREFUeAHtwYFOXFcAQ8Fjyf//y+67qcJSsirKBvDSesZJmB4zVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlNlpspMlZkqM1VmqsxUmakyU2WmykyVmSozVWaqzFSZqTJTZabKTJWZKjNVBvGIMB/BTJUhPEJ8rvD/YKbKIB4Rvivxp8IjxD1mqsyDxMcIhzjCVwh/Sjwi3GOmyjyF8NXEEQ7xe8IjxD1mqkyZOMJnEjfhb+EQjxAfx0yVqQmH+HzhEM/ITJX5hsQjwiGO8Fo4RIOZKjNVZqrMVJmpMlNlpspMlZkqM1VmqsxUmakyU2WmykyVmSozVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlNlpsrMnxPvC3eZqTJfT7wVOsTHCO8Td5mpMuKrhWcRPoZ4X7jLTJUJX00c4RBH6BBHOMTnEneZqTLifyU8FzNVpkZ8lXCII/xK9JipMi3iSDjEEd4jHhd+kXCR6DFTZZ6BOMJFHOEQH0kc4QeJS0KbmSpTJi7hRTjEEQ7xuHCII7wSfhBtZqpMlzgSLhKXhH8Kh/g94Sa8InEJh6gzU2WegcQl4SIBSfhJHOEtcRNuxCGO8IrEJeEi8RzMVJnnIXFJuEhcEiAc4t+It8IrEpeEi8QzMVNlno3EJeEi8VMSfovEi4SLxPMxU2Wek8QlHOKQeBF+CDfiIm7CjcSzMlNlnpm4SXghcYg3El5IfAdmqsx3IfFGuBGHxHdjpsp8X+I/wEyVmSozVWaqzFSZqTJTZabKTJWZKjNVZqrMVJmpMlP1FykJYQ+7D9AbAAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(255.0,0.0,0.0)      …  RGB{Float64}(217.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(223.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(219.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(223.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(226.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)      …  RGB{Float64}(221.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(225.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(229.0,0.0,0.0)\n",
              " RGB{Float64}(255.0,0.0,0.0)         RGB{Float64}(228.0,0.0,0.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show the images in the dataset\n",
        "using Images\n",
        "function show_images(dataset)\n",
        "    random_idx = rand(1:100, 10)\n",
        "    for i in random_idx\n",
        "        img = dataset[i,:,:,:]\n",
        "        img = permutedims(img, [3,1,2])\n",
        "        img_float = float(img) # Convert image to float\n",
        "        display(Images.colorview(RGB, img_float))\n",
        "    end\n",
        "end\n",
        "\n",
        "# show the images in the dataset\n",
        "show_images(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PyObject <Figure size 3000x3000 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_images_grid(imgs_, num_images=25):\n",
        "  imgs_ = imgs_ / 255. # normalise values to range [0,1]\n",
        "  imgs_ = imgs_.astype(np.float32)\n",
        "  ncols = int(np.ceil(num_images**0.5))\n",
        "  nrows = int(np.ceil(num_images / ncols))\n",
        "  fig, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for ax_i, ax in enumerate(axes):\n",
        "    if ax_i < num_images:\n",
        "      ax.imshow(imgs_[ax_i], cmap='Greys_r', interpolation='nearest')\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "    else:\n",
        "      ax.axis('off')\n",
        "  return fig\n",
        "\"\"\"\n",
        "\n",
        "display(py\"show_images_grid\"(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "ename": "PyCall.PyError",
          "evalue": "PyError ($(Expr(:escape, :(ccall(#= /Users/dongyu/.julia/packages/PyCall/KLzIO/src/pyeval.jl:34 =# @pysym(:Py_CompileString), PyPtr, (Cstring, Cstring, Cint), s, fname, input_type))))) <class 'SyntaxError'>\nSyntaxError('invalid syntax', ('/Users/dongyu/.julia/packages/PyCall/KLzIO/src/pyeval.jl', 5, 14, 'const _namespaces = Dict{Module,PyDict{String,PyObject,true}}()\\n', 5, 15))\n",
          "output_type": "error",
          "traceback": [
            "PyError ($(Expr(:escape, :(ccall(#= /Users/dongyu/.julia/packages/PyCall/KLzIO/src/pyeval.jl:34 =# @pysym(:Py_CompileString), PyPtr, (Cstring, Cstring, Cint), s, fname, input_type))))) <class 'SyntaxError'>\n",
            "SyntaxError('invalid syntax', ('/Users/dongyu/.julia/packages/PyCall/KLzIO/src/pyeval.jl', 5, 14, 'const _namespaces = Dict{Module,PyDict{String,PyObject,true}}()\\n', 5, 15))\n",
            "\n",
            "\n",
            "Stacktrace:\n",
            " [1] pyerr_check\n",
            "   @ ~/.julia/packages/PyCall/KLzIO/src/exception.jl:75 [inlined]\n",
            " [2] pyerr_check\n",
            "   @ ~/.julia/packages/PyCall/KLzIO/src/exception.jl:79 [inlined]\n",
            " [3] _handle_error(msg::String)\n",
            "   @ PyCall ~/.julia/packages/PyCall/KLzIO/src/exception.jl:96\n",
            " [4] macro expansion\n",
            "   @ ~/.julia/packages/PyCall/KLzIO/src/exception.jl:110 [inlined]\n",
            " [5] pyeval_(s::String, globals::PyDict{String, PyObject, true}, locals::PyDict{String, PyObject, true}, input_type::Int64, fname::String)\n",
            "   @ PyCall ~/.julia/packages/PyCall/KLzIO/src/pyeval.jl:34\n",
            " [6] top-level scope\n",
            "   @ ~/.julia/packages/PyCall/KLzIO/src/pyeval.jl:230"
          ]
        }
      ],
      "source": [
        "\n",
        "py\"\"\"\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import tensorflow_datasets as tfds\n",
        "train_data = %julia train_data\n",
        "test_data = %julia test_data\n",
        "\n",
        "def mask_image_random(n):\n",
        "    random_arrays = []\n",
        "    for i in range(n):\n",
        "        random_array = np.random.uniform(-1, 1, size=(64, 64, 3))\n",
        "        random_arrays.append(random_array)\n",
        "    return random_arrays\n",
        "\n",
        "def display(array1, array2, seed=None, title='Inputs and outputs of the model', n=10):\n",
        "    hopfield = False\n",
        "\n",
        "    dim = array1[0].shape[0]\n",
        "    # Displays ten random images from each one of the supplied arrays.\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        if hopfield is True:\n",
        "            plt.imshow(image1.reshape(dim, dim), cmap='binary', vmin=-1, vmax=1)\n",
        "        else:\n",
        "            plt.imshow(image1)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        if hopfield is True:\n",
        "            plt.imshow(image2.reshape(dim, dim), cmap='binary', vmin=-1, vmax=1)\n",
        "        else:\n",
        "            plt.imshow(image2)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    fig.suptitle(title)\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def load_tfds_dataset(dataset, num=15000, labels=False, key_dict={'shapes3d': 'label_shape'}):\n",
        "    dim = dims_dict[dataset]\n",
        "    ds = tfds.load(dataset, split='train', shuffle_files=False, data_dir='./data/')\n",
        "    ds_info = tfds.builder(dataset).info\n",
        "    df = tfds.as_dataframe(ds.take(num), ds_info)\n",
        "    data = df['image'].tolist()\n",
        "\n",
        "    key = key_dict[dataset]\n",
        "    labels_arr = df[key].to_numpy()\n",
        "\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(data, labels_arr, test_size=0.1,\n",
        "                                                                        random_state=42)\n",
        "\n",
        "    train_data = np.array(train_data).reshape(len(train_data), dim[0], dim[1], 3)\n",
        "    test_data = np.array(test_data).reshape(len(test_data), dim[0], dim[1], 3)\n",
        "\n",
        "    if labels:\n",
        "        return train_data, test_data, train_labels, test_labels\n",
        "    else:\n",
        "        return train_data, test_data\n",
        "\n",
        "def preprocess(array):\n",
        "    # Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    array = array.astype(\"float64\") / 255.0\n",
        "    return array\n",
        "\n",
        "def prepare_data(dataset, display=False, noise_factor=0.6, labels=False,train_data=train_data, test_data=test_data):\n",
        "    # Normalize and reshape the data\n",
        "    train_data = preprocess(train_data)\n",
        "    test_data = preprocess(test_data)\n",
        "\n",
        "    # Create a copy of the data with added noise\n",
        "    noisy_train_data = noise(train_data, noise_factor=noise_factor)\n",
        "    noisy_test_data = noise(test_data, noise_factor=noise_factor)\n",
        "\n",
        "    # Display the train data and a version of it with added noise\n",
        "    if display is True:\n",
        "        display(train_data, noisy_train_data)\n",
        "\n",
        "    if labels is False:\n",
        "        return train_data, test_data, noisy_train_data, noisy_test_data\n",
        "\n",
        "def plot_history(history, decoding_history, titles=False):\n",
        "    recon_loss_values = history.history['reconstruction_loss']\n",
        "    decoding_acc_values = decoding_history.decoding_history\n",
        "    epochs = range(1, len(recon_loss_values) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.set_ylim(0, 1)\n",
        "    ax.set_ylabel(\"Reconstruction error\")\n",
        "    ax2.set_ylabel(\"Decoding accuracy\")\n",
        "\n",
        "    ax.plot(epochs, recon_loss_values, label='Reconstruction Error', color='red')\n",
        "    ax2.plot(epochs, decoding_acc_values, label='Decoding Accuracy', color='blue')\n",
        "\n",
        "    if titles is True:\n",
        "        lines, labels = ax.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
        "        plt.title('Reconstruction error and decoding accuracy over time')\n",
        "\n",
        "    ax.set_xlabel('Epoch')\n",
        "    plt.show()\n",
        "    return fig\n",
        "    \n",
        "def noise(array, noise_factor=0.4, seed=None, gaussian=False, replacement_val=0):\n",
        "    # Replace a fraction noise_factor of pixels with replacement_val or gaussian noise\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    shape = array.shape\n",
        "    array = array.flatten()\n",
        "    indices = np.random.choice(np.arange(array.size), replace=False,\n",
        "                               size=int(array.size * noise_factor))\n",
        "    if gaussian is True:\n",
        "        array[indices] = np.random.normal(loc=0.5, scale=1.0, size=array[indices].shape)\n",
        "    else:\n",
        "        array[indices] = replacement_val\n",
        "    array = array.reshape(shape)\n",
        "    return np.clip(array, 0.0, 1.0)\n",
        "\n",
        "def check_generative_recall(vae, test_data, noise_level=0.1):\n",
        "    test_data = noise(test_data, noise_factor=noise_level)\n",
        "    latents = vae.encoder.predict(test_data)\n",
        "    predictions = vae.decoder.predict(latents[0])\n",
        "    fig = display(test_data, predictions, title='Inputs and outputs for VAE')\n",
        "    return fig\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hopfield network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "class ContinuousHopfield:\n",
        "    def __init__(self, pat_size, beta=100, do_normalization=True):\n",
        "        self.size = pat_size  # size of individual pattern\n",
        "        self.beta = beta\n",
        "        print(self.beta)\n",
        "        self.max_norm = np.sqrt(self.size)\n",
        "        if do_normalization:\n",
        "            self.softmax = self.softmax_normalized\n",
        "            self.energy = self.energy_normalized\n",
        "        else:\n",
        "            self.softmax = self.softmax_unnormalized\n",
        "            self.energy = self.energy_unnormalized\n",
        "\n",
        "        return\n",
        "\n",
        "    def learn(self, patterns):\n",
        "        # expects patterns as numpy arrays and stores them col-wise in pattern matrix \n",
        "        self.num_pat = len(patterns)\n",
        "        assert (all(type(x) is np.ndarray for x in patterns)), 'not all input patterns are numpy arrays'\n",
        "        assert (all(len(x.shape) == 2 for x in patterns)), 'not all input patterns have dimension 2'\n",
        "        assert (all(1 == x.shape[1] for x in patterns)), 'not all input patterns have shape (-1,1) '\n",
        "        self.patterns = np.array(patterns).squeeze(axis=-1).T  # save patterns col-wise\n",
        "        # without squeeze axis would result in problem with one pattern\n",
        "        # return -1*np.sum(np.exp([(self.patterns[:,ii].T @pattern)/self.max_norm for ii in range(self.patterns.shape[1])]))\n",
        "        self.M = max(np.linalg.norm(vec) for vec in patterns)  # maximal norm of actually stored patterns\n",
        "        return\n",
        "\n",
        "    def retrieve(self, partial_pattern, max_iter=np.inf, thresh=0.5):\n",
        "        # partial patterns have to be provided with None/0 at empty spots\n",
        "        if partial_pattern.size != self.size:\n",
        "            raise ValueError(\"Input pattern %r does not match state size: %d vs %d\"\n",
        "                             % (partial_pattern, len(partial_pattern), self.size))\n",
        "\n",
        "        if None in partial_pattern:\n",
        "            raise NotImplementedError(\"None elements not supported\")\n",
        "\n",
        "        assert type(partial_pattern) == np.ndarray, 'test pattern was not numpy array'\n",
        "        assert len(partial_pattern.shape) == 2 and 1 == partial_pattern.shape[\n",
        "            1], 'test pattern with shape %r is not a col-vector' % (partial_pattern.shape,)\n",
        "\n",
        "        pat_old = partial_pattern.copy()\n",
        "        iters = 0\n",
        "\n",
        "        while iters < max_iter:\n",
        "            pat_new = self.patterns @ self.softmax(self.beta * self.patterns.T @ pat_old)\n",
        "\n",
        "            if np.count_nonzero(pat_old != pat_new) <= thresh:  # converged\n",
        "                break\n",
        "            else:\n",
        "                pat_old = pat_new\n",
        "            iters += 1\n",
        "\n",
        "        return pat_new\n",
        "\n",
        "    def softmax_unnormalized(z):\n",
        "        return softmax(z)  # Scipy's softmax is numerically stable\n",
        "\n",
        "    def softmax_normalized(self, z):\n",
        "        return softmax(z / self.max_norm)\n",
        "\n",
        "    @staticmethod\n",
        "    def _lse(z, beta):\n",
        "        return 1 / beta * np.log(np.sum(np.exp(beta * z)))\n",
        "\n",
        "    def energy_unnormalized(self, pattern):\n",
        "        return -1 * self._lse(self.patterns.T @ pattern, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_normalized(self, pattern):\n",
        "        # normalize dot product of patterns by 1/sqrt(pattern_size)\n",
        "        return -1 * self._lse((self.patterns.T @ pattern) / self.max_norm, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_landscape(self):\n",
        "        for pat in product([1, -1], repeat=self.size):\n",
        "            pat = np.array(pat)\n",
        "            print(\"energy(%r)=%.3f\" % (pat, self.energy(pat)))\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "pat_size = 64*64*3\n",
        "net = py\"ContinuousHopfield\"(pat_size)\n",
        "net.learn(converted_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape before reshaping: (64, 64, 3)\n",
            "shape after reshaping: "
          ]
        },
        {
          "data": {
            "text/plain": [
              "PyObject <Figure size 2880x800 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12288, 1)\n",
            "Sampling from modern Hopfield network."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        }
      ],
      "source": [
        "n = 10000\n",
        "np = py\"np\"\n",
        "images_masked_np = py\"mask_image_random\"(n)\n",
        "println(\"shape before reshaping: \", size(images_masked_np[1]))\n",
        "images_masked_np = [reshape(array, (64*64*3,1)) for array in images_masked_np]\n",
        "println(\"shape after reshaping: \", size(images_masked_np[1]))\n",
        "\n",
        "print(\"Sampling from modern Hopfield network.\")\n",
        "predictions = []\n",
        "tests = []\n",
        "for test_ind in 1:n\n",
        "    test = images_masked_np[test_ind]\n",
        "    reconstructed = net.retrieve(test, max_iter=10)\n",
        "\n",
        "    reconstructed = reshape(reconstructed, (1, 64, 64, 3))\n",
        "    reconstructed = (reconstructed .+ 1) / 2\n",
        "    push!(predictions, reconstructed)\n",
        "    test = reshape(test, (1, 64, 64, 3))\n",
        "    test = (test .+ 1) / 2\n",
        "    push!(tests, test)\n",
        "end\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "tests = np.concatenate(tests, axis=0)\n",
        "\n",
        "display(py\"display\"(tests, predictions,n=10, title=\"Inputs and outputs of the Hopfield network\"))\n",
        "\n",
        "# rescale predictions back to interval [0, 1]\n",
        "predictions = (predictions .+ 1) / 2\n",
        "\n",
        "# save the predictions\n",
        "using JLD\n",
        "save(\"predictions.jld\", \"predictions\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzAy1LrF4a9T"
      },
      "source": [
        "# Variational Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class VAE(keras.Model):\n",
        "\n",
        "    def __init__(self, encoder, decoder, kl_weighting=1, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.kl_weighting = kl_weighting\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = reconstruction_loss_fn(data, reconstruction)\n",
        "            kl_loss = kl_loss_fn(z_mean, z_log_var, self.kl_weighting)\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "def label_classifier(latents, labels, num=200):\n",
        "        np.random.seed(1)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(latents[0], labels,\n",
        "                                                            test_size=0.5, random_state=1)\n",
        "        clf = make_pipeline(StandardScaler(), SVC())\n",
        "        clf.fit(x_train[0:num], y_train[0:num])\n",
        "        score = clf.score(x_test, y_test)\n",
        "        return score\n",
        "    \n",
        "class DecodingHistory(keras.callbacks.Callback):\n",
        "    \n",
        "        def __init__(self, dataset):\n",
        "            _, self.test_data, _, _, _, self.test_labels = prepare_data(dataset, labels=True)\n",
        "            self.decoding_history = []\n",
        "    \n",
        "        def on_epoch_begin(self, epoch, logs=None):\n",
        "            latents = self.model.encoder.predict(self.test_data)\n",
        "            score = label_classifier(latents, self.test_labels)\n",
        "            self.decoding_history.append(score)\n",
        "    \n",
        "    \n",
        "class Sampling(layers.Layer):\n",
        "        # Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
        "    \n",
        "        def call(self, inputs):\n",
        "            z_mean, z_log_var = inputs\n",
        "            batch = tf.shape(z_mean)[0]\n",
        "            dim = tf.shape(z_mean)[1]\n",
        "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "def encoder_network_large(input_shape, latent_dim=100):\n",
        "    input_img = layers.Input(shape=input_shape)\n",
        "    x = layers.Dropout(0.2, input_shape=input_shape)(input_img)\n",
        "    x = layers.Conv2D(32, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim, name='mean')(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "    encoder = keras.Model(input_img, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "    return encoder, z_mean, z_log_var\n",
        "\n",
        "\n",
        "def decoder_network_large(latent_dim=100):\n",
        "    decoder_input = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(4096)(decoder_input)\n",
        "    x = layers.Reshape((4, 4, 256))(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(32, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "    decoder = keras.Model(decoder_input, x)\n",
        "    return decoder\n",
        "\n",
        "\n",
        "def build_encoder_decoder_large(latent_dim=5):\n",
        "    input_shape = (64, 64, 3)\n",
        "    encoder, z_mean, z_log_var = encoder_network_large(input_shape, latent_dim)\n",
        "    decoder = decoder_network_large(latent_dim)\n",
        "    return encoder, decoder\n",
        "\n",
        "def kl_loss_fn(z_mean, z_log_var, kl_weighting):\n",
        "    # take the sum across the n latent variables\n",
        "    # then take the mean across the batch\n",
        "    kl = K.mean(-0.5 * K.sum(1 + z_log_var \\\n",
        "                             - K.square(z_mean) \\\n",
        "                             - K.exp(z_log_var), axis=-1))\n",
        "    return kl_weighting * kl\n",
        "\n",
        "\n",
        "def reconstruction_loss_fn(x, t_decoded):\n",
        "    # mean_absolute_error() returns result of dim (n_in_batch, pixels)\n",
        "    # take the sum across the 64x64x3 pixels\n",
        "    # take the mean across the batch\n",
        "    data = x\n",
        "    reconstruction = t_decoded\n",
        "    # note that binary_crossentropy loss also gives good results\n",
        "    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(\n",
        "        keras.losses.mean_absolute_error(data, reconstruction), axis=(1, 2)))\n",
        "    return reconstruction_loss\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to train VAE.Input data shape:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 64, 64, 3)\n",
            "Training data shape:(100, 64, 64, 3)\n",
            "Test data shape:(10, 64, 64, 3)\n",
            "Epoch 1/10\n",
            "4/4 - 1s - loss: 1476.8820 - reconstruction_loss: 1460.7684 - kl_loss: 16.1136 - 864ms/epoch - 216ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 1274.6477 - reconstruction_loss: 1266.0964 - kl_loss: 8.5513 - 278ms/epoch - 70ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 1176.5393 - reconstruction_loss: 1159.4667 - kl_loss: 17.0727 - 276ms/epoch - 69ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 1112.8025 - reconstruction_loss: 1094.8953 - kl_loss: 17.9073 - 272ms/epoch - 68ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 1093.7417 - reconstruction_loss: 1074.1333 - kl_loss: 19.6084 - 277ms/epoch - 69ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 1016.1420 - reconstruction_loss: 1006.8064 - kl_loss: 9.3356 - 277ms/epoch - 69ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 950.2487 - reconstruction_loss: 942.1019 - kl_loss: 8.1467 - 280ms/epoch - 70ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 901.9321 - reconstruction_loss: 883.7780 - kl_loss: 18.1541 - 275ms/epoch - 69ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 844.0853 - reconstruction_loss: 827.1007 - kl_loss: 16.9846 - 277ms/epoch - 69ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 836.8937 - reconstruction_loss: 823.5664 - kl_loss: 13.3273 - 275ms/epoch - 69ms/step\n",
            "Recalling noisy images with the generative model:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r1/4 [======>.......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 0s 4ms/step\n",
            "\r1/4 [======>.......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 0s 12ms/step\n",
            "\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 57ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3-element Vector{Matrix{Float32}}:\n",
              " [313.31528 -278.5594 … 191.9347 3.251748; 352.3253 -376.8465 … 465.98773 84.85992; … ; -137.33273 120.101845 … 100.2371 -734.63245; 150.43137 -221.3535 … -174.72945 -46.758705]\n",
              " [-349.0673 -268.46472 … -386.87872 -578.7492; -464.64233 -370.1719 … -575.8431 -810.7547; … ; -669.5571 -309.8216 … -435.395 -627.7201; -346.9865 -351.26807 … -519.7041 -688.85455]\n",
              " [313.31528 -278.5594 … 191.9347 3.251748; 352.3253 -376.8465 … 465.98773 84.85992; … ; -137.33273 120.101845 … 100.2371 -734.63245; 150.43137 -221.3535 … -174.72945 -46.758705]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "latent_dim = 5\n",
        "keras = py\"keras\"\n",
        "kl_weighting=1\n",
        "lr=0.001\n",
        "generative_epochs=10\n",
        "pickle = pyimport(\"pickle\")\n",
        "dataset = \"shapes3d\"\n",
        "print(\"Starting to train VAE.\")\n",
        "# build VAE with latent_dim latent variables\n",
        "encoder, decoder = py\"build_encoder_decoder_large\"(latent_dim=latent_dim)\n",
        "vae = py\"VAE\"(encoder, decoder, kl_weighting)\n",
        "# jit_compile set to False to run on MacOS\n",
        "opt = keras.optimizers.Adam(lr=lr, amsgrad=1, jit_compile=0)\n",
        "vae.compile(optimizer=opt)\n",
        "# decoding_history = py\"DecodingHistory\"(dataset)\n",
        "# history = keras.callbacks.History()\n",
        "# stop training if no loss improvement for three epochs\n",
        "# early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "println(\"Input data shape:\", size(predictions))\n",
        "println(\"Training data shape:\", size(train_data))\n",
        "println(\"Test data shape:\", size(test_data))\n",
        "\n",
        "# fit VAE\n",
        "vae.fit(predictions, epochs=generative_epochs, verbose=2, batch_size=32)\n",
        "\n",
        "vae.encoder.save_weights(\"model_weights/100_encoder.h5\")\n",
        "vae.decoder.save_weights(\"model_weights/100_decoder.h5\")\n",
        "\n",
        "# diplay(py\"plot_history\"(history, decoding_history))\n",
        "\n",
        "# pickle.dump(history.history['reconstruction_loss'], open(\"./outputs/history.pkl\", \"wb\"))\n",
        "# pickle.dump(decoding_history.decoding_history, open(\"./outputs/decoding.pkl\", \"wb\"))\n",
        "\n",
        "print(\"Recalling noisy images with the generative model:\")\n",
        "fig = py\"check_generative_recall\"(vae, train_data)\n",
        "\n",
        "latents = vae.encoder.predict(test_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia 1.9.3",
      "language": "julia",
      "name": "julia-1.9"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
