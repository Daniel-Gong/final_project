{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m Conda ─→ `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/51cab8e982c5b598eea9c8ceaced4b58d9dd37c9/build.log`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m PyCall → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/1cb97fa63a3629c6d892af4f76fcc4ad8191837c/build.log`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "using Flux\n",
        "using Hopfields\n",
        "using HDF5\n",
        "using PyCall\n",
        "using JLD\n",
        "using Images\n",
        "\n",
        "ENV[\"PYTHON\"] = \"/Users/dongyu/opt/anaconda3/envs/modeling/bin/python\"\n",
        "Pkg.build(\"PyCall\")\n",
        "println(PyCall.python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "function load_shapes3d_dataset(file_path, type =\"train\")\n",
        "    random_idx = rand(1:480000, 100)\n",
        "    if type == \"test\"\n",
        "        random_idx = rand(1:480000, 10)\n",
        "    end\n",
        "    dataset = h5open(file_path, \"r\") do file\n",
        "        read(file[\"images\"])[:, :, :, random_idx]\n",
        "    end\n",
        "    dataset = permutedims(dataset, [4, 3, 2, 1])\n",
        "    println(\"Dataset shape: \", size(dataset))\n",
        "    # Convert and reshape the dataset to a list of 1d vectors\n",
        "    converted_dataset = ((dataset ./ 255) .* 2) .- 1\n",
        "    converted_dataset = [reshape(converted_dataset[i,:,:,:], (64*64*3,1)) for i in 1:size(converted_dataset)[1]]\n",
        "    println(\"Converted dataset shape: \", size(converted_dataset))\n",
        "    return dataset, converted_dataset\n",
        "end\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (100, 64, 64, 3)\n",
            "Converted dataset shape: (100,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "train_data,converted_train_data = load_shapes3d_dataset(\"3dshapes.h5\", \"train\")\n",
        ";\n",
        "\n",
        "# save the dataset\n",
        "save(\"train_data.jld2\", \"train_data\", train_data)\n",
        "save(\"converted_train_data.jld2\", \"converted_train_data\", converted_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (10, 64, 64, 3)\n",
            "Converted dataset shape: (10,)\n"
          ]
        }
      ],
      "source": [
        "test_data,convert_test_data = load_shapes3d_dataset(\"3dshapes.h5\", \"test\")\n",
        ";\n",
        "\n",
        "# save the dataset\n",
        "save(\"test_data.jld2\", \"test_data\", test_data)\n",
        "save(\"convert_test_data.jld2\", \"convert_test_data\", convert_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiFJREFUeAHtwYFuGlEUQ8Fjyf//y7d9UhUKRYTskjWbesYzQ+WYijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqKMxI0Z6iimoswMNyR2mqHukrhmKspI3JhhJ4nNZvgBJO6a4ZqpKPMviZ1m2ExipxkOI3HXDHdJXDMVZb6DxGYz7CSx2Qw3JB6Y4S6J55iKMu9GYqcZNpO4McMDEvuYijI/j8RmM9yQ+E6mokz9TeJYpqJMRZmKMinDexERpqJMiqjfTEWZ483wSuKFxMFMRZljDIs4h2ERBzAVZSrKVJSpKFNRpqJMRZmKMhVlKspUlDm9YRHnZCrKnJ44M1NRpqJMRZn6Y9hC7GMqyrzMcG5iu+Fz4h5TUYbhNcSzhncxLGIZthPPGq6ZijKI1xj+X8OzxDVTUYahjjNcMxVlTm9YxDmZijIVZSrKnJ44M1NRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWVOb1jEOZmKMsWQYyrKnJ7YYrgQy5BgKsocQyzDNxieJS7ExfBhWMRhTEWZI4llWMQy7CC+ZrhLLMMiDmYqyhxPLMMiLoYvGm6JZfiUuBgWEWEqyqSIZbgQjwxPGD6IR4YLEWQqymSJi+ER8TXDI+JNmIoy70M8MnyNOAVTUeYsxI9kKspUlKkoU1GmokxFmYr6BXmFTgorXO/KAAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiFJREFUeAHtwYFuGlEUQ8Fjyf//y7d9UhUKRYTskjWbesYzQ+WYijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqKMxI0Z6iimoswMNyR2mqHukrhmKspI3JhhJ4nNZvgBJO6a4ZqpKPMviZ1m2ExipxkOI3HXDHdJXDMVZb6DxGYz7CSx2Qw3JB6Y4S6J55iKMu9GYqcZNpO4McMDEvuYijI/j8RmM9yQ+E6mokz9TeJYpqJMRZmKMinDexERpqJMiqjfTEWZ483wSuKFxMFMRZljDIs4h2ERBzAVZSrKVJSpKFNRpqJMRZmKMhVlKspUlDm9YRHnZCrKnJ44M1NRpqJMRZn6Y9hC7GMqyrzMcG5iu+Fz4h5TUYbhNcSzhncxLGIZthPPGq6ZijKI1xj+X8OzxDVTUYahjjNcMxVlTm9YxDmZijIVZSrKnJ44M1NRpqJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWVOb1jEOZmKMsWQYyrKnJ7YYrgQy5BgKsocQyzDNxieJS7ExfBhWMRhTEWZI4llWMQy7CC+ZrhLLMMiDmYqyhxPLMMiLoYvGm6JZfiUuBgWEWEqyqSIZbgQjwxPGD6IR4YLEWQqymSJi+ER8TXDI+JNmIoy70M8MnyNOAVTUeYsxI9kKspUlKkoU1GmokxFmYr6BXmFTgorXO/KAAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(66.0,0.0,255.0)     …  RGB{Float64}(44.0,0.0,220.0)\n",
              " RGB{Float64}(66.0,0.0,255.0)        RGB{Float64}(45.0,0.0,225.0)\n",
              " RGB{Float64}(67.0,0.0,255.0)        RGB{Float64}(45.0,0.0,220.0)\n",
              " RGB{Float64}(64.0,0.0,255.0)        RGB{Float64}(44.0,0.0,220.0)\n",
              " RGB{Float64}(66.0,0.0,255.0)        RGB{Float64}(44.0,0.0,221.0)\n",
              " RGB{Float64}(64.0,0.0,255.0)     …  RGB{Float64}(47.0,0.0,233.0)\n",
              " RGB{Float64}(63.0,0.0,255.0)        RGB{Float64}(47.0,0.0,235.0)\n",
              " RGB{Float64}(64.0,0.0,255.0)        RGB{Float64}(47.0,0.0,233.0)\n",
              " RGB{Float64}(63.0,0.0,255.0)        RGB{Float64}(45.0,0.0,227.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAdZJREFUeAHtwVGOalcQBMFsKfe/5baO/IE1QoP9ZrgFuCLcXSpHKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKhmOpCKkoWY7hvS1vSipKhmN5b8ObkoqSvw3vbXlTUlHyGYY3JRUlFSUVJRUlFSUVJRUlWctjwweTipIrLfWFVJS8vuUYPpJUlFSUVJRUlFSUvL7hg0lFSUVJRUlFSUVJRUlFSUVJRcnrW47hI0lFSUVJRUlFSUXJsy0/NVxneWz4RVJR8mzDV8vrGh5bfpFUlCx1LBFSUfJkw1fL6xquJhXl8FzLO1muMxxSUS5XGI7lPQzXkYpyeK6lviMVJRUlFSWvbzmGjyQVJRUlFSUVJRUlr2/4YFJRUlFSUVJRUlFSUVJR8n+2HEOQVJQ82XAsP7Acw08tx3Az3LUcwxWkouQSw7Ecw7H8a8OxfGd4bLhZvhiO5RiuIxUlFxqO5Rhulm8tx/DfLA8NN8sxXE0qSi43HMvNcN/yD8sfG+5bboYMqSgJGW6W+4bfsdw35ElFyQsY7lt+x/C6pKLkhQ2fTypKKkoqSipKKkoqSirqL/O0MQXaCqlSAAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAdZJREFUeAHtwVGOalcQBMFsKfe/5baO/IE1QoP9ZrgFuCLcXSpHKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKhmOpCKkoWY7hvS1vSipKhmN5b8ObkoqSvw3vbXlTUlHyGYY3JRUlFSUVJRUlFSUVJRUlWctjwweTipIrLfWFVJS8vuUYPpJUlFSUVJRUlFSUvL7hg0lFSUVJRUlFSUVJRUlFSUVJRcnrW47hI0lFSUVJRUlFSUXJsy0/NVxneWz4RVJR8mzDV8vrGh5bfpFUlCx1LBFSUfJkw1fL6xquJhXl8FzLO1muMxxSUS5XGI7lPQzXkYpyeK6lviMVJRUlFSWvbzmGjyQVJRUlFSUVJRUlr2/4YFJRUlFSUVJRUlFSUVJR8n+2HEOQVJQ82XAsP7Acw08tx3Az3LUcwxWkouQSw7Ecw7H8a8OxfGd4bLhZvhiO5RiuIxUlFxqO5Rhulm8tx/DfLA8NN8sxXE0qSi43HMvNcN/yD8sfG+5bboYMqSgJGW6W+4bfsdw35ElFyQsY7lt+x/C6pKLkhQ2fTypKKkoqSipKKkoqSirqL/O0MQXaCqlSAAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,127.0,255.0)    …  RGB{Float64}(0.0,87.0,219.0)\n",
              " RGB{Float64}(0.0,124.0,255.0)       RGB{Float64}(0.0,88.0,219.0)\n",
              " RGB{Float64}(0.0,126.0,255.0)       RGB{Float64}(0.0,89.0,223.0)\n",
              " RGB{Float64}(0.0,126.0,255.0)       RGB{Float64}(0.0,87.0,218.0)\n",
              " RGB{Float64}(0.0,121.0,255.0)       RGB{Float64}(0.0,90.0,223.0)\n",
              " RGB{Float64}(0.0,122.0,255.0)    …  RGB{Float64}(0.0,90.0,226.0)\n",
              " RGB{Float64}(0.0,122.0,255.0)       RGB{Float64}(0.0,88.0,220.0)\n",
              " RGB{Float64}(0.0,118.0,255.0)       RGB{Float64}(0.0,90.0,222.0)\n",
              " RGB{Float64}(0.0,111.0,255.0)       RGB{Float64}(0.0,91.0,227.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAX5JREFUeAHtwVlqG0AABcEe6PtfeYK+HALZQHZL+FV572U6MimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZzAFkUvLGDu/tAjIp4fCuLu/tADIp4fKuDu9PJiUcpiOTkknJpGRSMimZlExKJiWTkknJpCRzeS2HgkxKMocBmZRkLq/lUJBJyZe6PBx+7/DVLj+7PBy+ikxKXszle5FJyUs6fK7Lw+HhUpJJyaRkUjIpmZRMSiYlk5JJCZdnOsz/kEkJh2e6/N3lFV0+XL6KTEq4PNPhX11ey6Egk5Inu7yrS0Em5aFxKR0+HP7k8rlkUvJUl3d1+dXh4fC5ZFLyVId/dXkth4ZMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpiRw+XL4vmZS8gMP3JZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTOoHWcIe/xFZDBoAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAX5JREFUeAHtwVlqG0AABcEe6PtfeYK+HALZQHZL+FV572U6MimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZzAFkUvLGDu/tAjIp4fCuLu/tADIp4fKuDu9PJiUcpiOTkknJpGRSMimZlExKJiWTkknJpCRzeS2HgkxKMocBmZRkLq/lUJBJyZe6PBx+7/DVLj+7PBy+ikxKXszle5FJyUs6fK7Lw+HhUpJJyaRkUjIpmZRMSiYlk5JJCZdnOsz/kEkJh2e6/N3lFV0+XL6KTEq4PNPhX11ey6Egk5Inu7yrS0Em5aFxKR0+HP7k8rlkUvJUl3d1+dXh4fC5ZFLyVId/dXkth4ZMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpiRw+XL4vmZS8gMP3JZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTOoHWcIe/xFZDBoAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,255.0,255.0)    …  RGB{Float64}(0.0,218.0,218.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,215.0,215.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,220.0,220.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,222.0,222.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,216.0,216.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)    …  RGB{Float64}(0.0,219.0,219.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,221.0,221.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,216.0,216.0)\n",
              " RGB{Float64}(0.0,255.0,255.0)       RGB{Float64}(0.0,207.0,207.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiZJREFUeAHtwYFq41AUQ8Ej0P//8l3eQvHSNWnipFYcNOOZoXJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFWRwx1GuYivJwhEgaPoepKIsjhiSRNBwh9pmKMoeIpCFJHDF8JxZTUeaCRN7wGLHPVJSpQ8RrmIoyFWUqylSUqSgTMrwXkWEqyoSIWkxFmdMN70uczVSUOcWwiEPEbxl2DYs4g6ko8/6G3yI2Q4SpKHMt4pWGOFNRpsQyRJiKMhVlKspUlKkoU1GmosxViI9kKspcxbCID2MqylyFeFvDz8Q+U1HmbsOzhicMiziBeIx4zLAxFeXhXuK4YRHL8L6GM4iNqSiLew3PGj6V+NnwZdiYivJQ/xLHDfvEIvaYijKIsw3vbljEY8S9hi+mogzDY8QRwyIOEx9EfDEVZRCVYyrKXMWwiA9jKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaizFWI3zIEmYoyVzEs4jWGjViGCFNR5iRiGZ40bMS+YZ/YiM3wl1iGRZzFVJQ5lViGRSzDDeKWYZ+4ZfiPWIZFnMtUlAkQy7CIzfDNcIvYN9xBbIZFJJiKMjFiGTbiluGb4SZxy7AROaaiTJjYDLeIxwz7xCLeg6ko80bEz4afiUVcgakoczHis5iKMhVlKspUlKkoU1Gmov4Anr5GCbjgY6YAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiZJREFUeAHtwYFq41AUQ8Ej0P//8l3eQvHSNWnipFYcNOOZoXJMRZmKMhVlKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaiTEWZijIVZSrKVJSpKFNRpqJMRZmKMhVlKspUlKkoU1GmokxFWRwx1GuYivJwhEgaPoepKIsjhiSRNBwh9pmKMoeIpCFJHDF8JxZTUeaCRN7wGLHPVJSpQ8RrmIoyFWUqylSUqSgTMrwXkWEqyoSIWkxFmdMN70uczVSUOcWwiEPEbxl2DYs4g6ko8/6G3yI2Q4SpKHMt4pWGOFNRpsQyRJiKMhVlKspUlKkoU1GmosxViI9kKspcxbCID2MqylyFeFvDz8Q+U1HmbsOzhicMiziBeIx4zLAxFeXhXuK4YRHL8L6GM4iNqSiLew3PGj6V+NnwZdiYivJQ/xLHDfvEIvaYijKIsw3vbljEY8S9hi+mogzDY8QRwyIOEx9EfDEVZRCVYyrKXMWwiA9jKspUlKkoU1GmokxFmYoyFWUqylSUqShTUaaizFWI3zIEmYoyVzEs4jWGjViGCFNR5iRiGZ40bMS+YZ/YiM3wl1iGRZzFVJQ5lViGRSzDDeKWYZ+4ZfiPWIZFnMtUlAkQy7CIzfDNcIvYN9xBbIZFJJiKMjFiGTbiluGb4SZxy7AROaaiTJjYDLeIxwz7xCLeg6ko80bEz4afiUVcgakoczHis5iKMhVlKspUlKkoU1Gmov4Anr5GCbjgY6YAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(253.0,255.0,0.0)    …  RGB{Float64}(174.0,217.0,0.0)\n",
              " RGB{Float64}(252.0,255.0,0.0)       RGB{Float64}(178.0,223.0,0.0)\n",
              " RGB{Float64}(247.0,255.0,0.0)       RGB{Float64}(175.0,219.0,0.0)\n",
              " RGB{Float64}(252.0,255.0,0.0)       RGB{Float64}(178.0,223.0,0.0)\n",
              " RGB{Float64}(252.0,255.0,0.0)       RGB{Float64}(181.0,226.0,0.0)\n",
              " RGB{Float64}(242.0,255.0,0.0)    …  RGB{Float64}(176.0,221.0,0.0)\n",
              " RGB{Float64}(243.0,255.0,0.0)       RGB{Float64}(180.0,225.0,0.0)\n",
              " RGB{Float64}(244.0,255.0,0.0)       RGB{Float64}(183.0,229.0,0.0)\n",
              " RGB{Float64}(238.0,255.0,0.0)       RGB{Float64}(183.0,228.0,0.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAatJREFUeAHtwUFuG0EQBMFsIP//5Tb2RENeU9BBqhFZEe4ulSMVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlDK9vOZVUlLC8vuFUUlHC8PqWU0lFyVsYTiUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSVhy08bTiIVJRUlFSW/xvCKpKKkoqSipKKkoqSipKKE5X0taVJRwpC3ZAxpUlHC8i6Wy3BZziAVJf8z/JwlY4iTipLh3vL6ljipKFnuDd9luQyXJW8IkoqSoYKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkouSNDOeRipK3s5xEKkpSli9aHoZnlnvDZbgsZ5CKkp83XJbLcFmeGu4tHw2X4d7ywRAnFSUpw8PwsPxj+Wi4DPeWJ4ajSEXJCZaH4d7yl+VTw73lYYiTipITDA/LveFrlnvDUaSi5DTDM8vnhsvwK0hFye8yvBipKKkoqSipKKkoqSipKKkoqag/PQgoBJjaNmIAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAatJREFUeAHtwUFuG0EQBMFsIP//5Tb2RENeU9BBqhFZEe4ulSMVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlDK9vOZVUlLC8vuFUUlHC8PqWU0lFyVsYTiUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSVhy08bTiIVJRUlFSW/xvCKpKKkoqSipKKkoqSipKKE5X0taVJRwpC3ZAxpUlHC8i6Wy3BZziAVJf8z/JwlY4iTipLh3vL6ljipKFnuDd9luQyXJW8IkoqSoYKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkouSNDOeRipK3s5xEKkpSli9aHoZnlnvDZbgsZ5CKkp83XJbLcFmeGu4tHw2X4d7ywRAnFSUpw8PwsPxj+Wi4DPeWJ4ajSEXJCZaH4d7yl+VTw73lYYiTipITDA/LveFrlnvDUaSi5DTDM8vnhsvwK0hFye8yvBipKKkoqSipKKkoqSipKKkoqag/PQgoBJjaNmIAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(250.0,0.0,255.0)    …  RGB{Float64}(177.0,0.0,222.0)\n",
              " RGB{Float64}(251.0,0.0,255.0)       RGB{Float64}(174.0,0.0,219.0)\n",
              " RGB{Float64}(252.0,0.0,255.0)       RGB{Float64}(176.0,0.0,221.0)\n",
              " RGB{Float64}(243.0,0.0,255.0)       RGB{Float64}(179.0,0.0,224.0)\n",
              " RGB{Float64}(244.0,0.0,255.0)       RGB{Float64}(174.0,0.0,218.0)\n",
              " RGB{Float64}(243.0,0.0,255.0)    …  RGB{Float64}(178.0,0.0,223.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)       RGB{Float64}(180.0,0.0,225.0)\n",
              " RGB{Float64}(232.0,0.0,255.0)       RGB{Float64}(177.0,0.0,221.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)       RGB{Float64}(175.0,0.0,219.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAgxJREFUeAHtwVFOHAEQQ8HXku9/ZWeaDwZNViJCYT0LrpJtKkdUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVHihxqWuTtRUeJHG67MGpbJExUlXtCwzGlY5vWIihK3NHxuuBr+lbmB4SAqSvwywzJrWObN8GzmICpKDBnmXsyzDQdRUcLUGpZZw9OIihLD85g1LFMHUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFR4hczeaKixC9j1rBMnqgo8XzmYlgmykSIihLPNCyzhmUOJmpYZg1PJipK3MCwzBq+izmZuxAVJZ5vWGYNB5vDsMwavsuwzJthmTVEiIoSWeadOZk1/B/mZD4wcaKiRMqwzBqWOQwns4avM2tY5oNhmTUEiYoSWcMyazjYvBuWuRoeM6dhDct8MCyzhjhRUeIOhmXWsMzBnIbPDSfzl2GZNdyEqChxH8MyaziZg/mS4WTWcCuiosTdDMuchivz2HBlTsMNiYoS9zSczNXwmLkabk5UlLi/4co8NrwcUVHiFQ0/hqgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSrqD+FaSP+j39x1AAAAAElFTkSuQmCC",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAgxJREFUeAHtwVFOHAEQQ8HXku9/ZWeaDwZNViJCYT0LrpJtKkdUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVHihxqWuTtRUeJHG67MGpbJExUlXtCwzGlY5vWIihK3NHxuuBr+lbmB4SAqSvwywzJrWObN8GzmICpKDBnmXsyzDQdRUcLUGpZZw9OIihLD85g1LFMHUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFRoqJERYmKEhUlKkpUlKgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSpKVJSoKFFR4hczeaKixC9j1rBMnqgo8XzmYlgmykSIihLPNCyzhmUOJmpYZg1PJipK3MCwzBq+izmZuxAVJZ5vWGYNB5vDsMwavsuwzJthmTVEiIoSWeadOZk1/B/mZD4wcaKiRMqwzBqWOQwns4avM2tY5oNhmTUEiYoSWcMyazjYvBuWuRoeM6dhDct8MCyzhjhRUeIOhmXWsMzBnIbPDSfzl2GZNdyEqChxH8MyaziZg/mS4WTWcCuiosTdDMuchivz2HBlTsMNiYoS9zSczNXwmLkabk5UlLi/4co8NrwcUVHiFQ0/hqgoUVGiokRFiYoSFSUqSlSUqChRUaKiREWJihIVJSrqD+FaSP+j39x1AAAAAElFTkSuQmCC\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(247.0,0.0,255.0)    …  RGB{Float64}(175.0,0.0,218.0)\n",
              " RGB{Float64}(244.0,0.0,255.0)       RGB{Float64}(172.0,0.0,215.0)\n",
              " RGB{Float64}(244.0,0.0,255.0)       RGB{Float64}(176.0,0.0,220.0)\n",
              " RGB{Float64}(233.0,0.0,255.0)       RGB{Float64}(178.0,0.0,222.0)\n",
              " RGB{Float64}(235.0,0.0,255.0)       RGB{Float64}(172.0,0.0,216.0)\n",
              " RGB{Float64}(234.0,0.0,255.0)    …  RGB{Float64}(175.0,0.0,219.0)\n",
              " RGB{Float64}(224.0,0.0,255.0)       RGB{Float64}(177.0,0.0,221.0)\n",
              " RGB{Float64}(223.0,0.0,255.0)       RGB{Float64}(173.0,0.0,216.0)\n",
              " RGB{Float64}(223.0,0.0,255.0)       RGB{Float64}(165.0,0.0,207.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAZVJREFUeAHtwUluGEgMBMEkkP//Mo0+zdGbNEVZFeHuUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRDpUkFeVSSVJRDpUkFSVfyvJzw1ciFSXnLc/wDL9qeYbrpKLksOUZnuX3DM/yDHdJRclJyzM8y59YnuFZnuEiqSg5ZnmGZ/lbyzM8yzPcIhUlxwzP8pGWZ7hIKkrOWJ7hcy3PcIVUlJwxPMtnWZ7hFqkoOWB5hg81PMszPMtBUlFSUVJR8rUM/xipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKJcrlv/DcotUlMMty+cabpGKcvlellukomS4aPkYw3+Gg6SiZPkuloOkomS4Zfksw0FSUVJRUlFSUVJRUlFSUXLN8CzfhFSU3DR8E1JRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRPwBXOyf93jqkVwAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAZVJREFUeAHtwUluGEgMBMEkkP//Mo0+zdGbNEVZFeHuUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRDpUkFeVSSVJRDpUkFSVfyvJzw1ciFSXnLc/wDL9qeYbrpKLksOUZnuX3DM/yDHdJRclJyzM8y59YnuFZnuEiqSg5ZnmGZ/lbyzM8yzPcIhUlxwzP8pGWZ7hIKkrOWJ7hcy3PcIVUlJwxPMtnWZ7hFqkoOWB5hg81PMszPMtBUlFSUVJR8rUM/xipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKJcrlv/DcotUlMMty+cabpGKcvlellukomS4aPkYw3+Gg6SiZPkuloOkomS4Zfksw0FSUVJRUlFSUVJRUlFSUXLN8CzfhFSU3DR8E1JRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRPwBXOyf93jqkVwAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(255.0,0.0,188.0)    …  RGB{Float64}(217.0,0.0,131.0)\n",
              " RGB{Float64}(255.0,0.0,190.0)       RGB{Float64}(223.0,0.0,135.0)\n",
              " RGB{Float64}(255.0,0.0,183.0)       RGB{Float64}(217.0,0.0,131.0)\n",
              " RGB{Float64}(255.0,0.0,184.0)       RGB{Float64}(221.0,0.0,134.0)\n",
              " RGB{Float64}(255.0,0.0,183.0)       RGB{Float64}(223.0,0.0,134.0)\n",
              " RGB{Float64}(255.0,0.0,175.0)    …  RGB{Float64}(217.0,0.0,131.0)\n",
              " RGB{Float64}(255.0,0.0,176.0)       RGB{Float64}(222.0,0.0,133.0)\n",
              " RGB{Float64}(255.0,0.0,176.0)       RGB{Float64}(223.0,0.0,134.0)\n",
              " RGB{Float64}(255.0,0.0,173.0)       RGB{Float64}(223.0,0.0,135.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAZBJREFUeAHtwUFu2wAQBMFeoP//5Y140kVwIoDWkNFUubtUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFTK8CAVJfc13NvyIBUlw10t9zY8SEXJclfDf0AqSoYKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSa1rONFyWVJRkLa8NZ1p+MgRJRUnW8NpypuGypKLk85bDcFg+YfnJcFgOw4dJRcklDZ+w5ElFyRdYrksqSr7A8LQchsOSJxUlFSUVJRUlFSXLmYZ6i1SUDGda/tVyFcvT8mFSUbKcaXjPkjcESUXJuZb7WYKkohySlk8bnoa/W36XVJScarmf5bXhMPwuqSg51fCeJW9IkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKo4Wn5RlJRchnDN5KKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSivoDxM4i/nklpGcAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAZBJREFUeAHtwUFu2wAQBMFeoP//5Y140kVwIoDWkNFUubtUjlSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFSUVJRUlFTK8CAVJfc13NvyIBUlw10t9zY8SEXJclfDf0AqSoYKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSa1rONFyWVJRkLa8NZ1p+MgRJRUnW8NpypuGypKLk85bDcFg+YfnJcFgOw4dJRcklDZ+w5ElFyRdYrksqSr7A8LQchsOSJxUlFSUVJRUlFSXLmYZ6i1SUDGda/tVyFcvT8mFSUbKcaXjPkjcESUXJuZb7WYKkohySlk8bnoa/W36XVJScarmf5bXhMPwuqSg51fCeJW9IkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSipKo4Wn5RlJRchnDN5KKkoqSipKKkoqSipKKkoqSipKKkoqSipKKkoqSivoDxM4i/nklpGcAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(0.0,255.0,123.0)    …  RGB{Float64}(0.0,218.0,88.0)\n",
              " RGB{Float64}(0.0,255.0,122.0)       RGB{Float64}(0.0,215.0,86.0)\n",
              " RGB{Float64}(0.0,255.0,122.0)       RGB{Float64}(0.0,220.0,88.0)\n",
              " RGB{Float64}(0.0,255.0,117.0)       RGB{Float64}(0.0,222.0,89.0)\n",
              " RGB{Float64}(0.0,255.0,118.0)       RGB{Float64}(0.0,216.0,87.0)\n",
              " RGB{Float64}(0.0,255.0,117.0)    …  RGB{Float64}(0.0,219.0,89.0)\n",
              " RGB{Float64}(0.0,255.0,113.0)       RGB{Float64}(0.0,221.0,89.0)\n",
              " RGB{Float64}(0.0,255.0,112.0)       RGB{Float64}(0.0,216.0,88.0)\n",
              " RGB{Float64}(0.0,255.0,112.0)       RGB{Float64}(0.0,207.0,83.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAS9JREFUeAHtwTFuwDAAxDAZ0P+/7KJT124KkiO99zIdmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlHN7v8lQyKeHyfoenkkkJh/e7PJVMSj7h8FQyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkJHP5r8N7yaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpyRz+XL5KJiWPcPhz+RKZlDzI5dfhS2RS8iCH75FJyaRkUjIpmZRMSiYlk5JJyaRkUj9s2gwAX+fBFwAAAABJRU5ErkJggg==",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAS9JREFUeAHtwTFuwDAAxDAZ0P+/7KJT124KkiO99zIdmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlHN7v8lQyKeHyfoenkkkJh/e7PJVMSj7h8FQyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkJHP5r8N7yaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpmZRMSiYlk5JJyaRkUjIpyRz+XL5KJiWPcPhz+RKZlDzI5dfhS2RS8iCH75FJyaRkUjIpmZRMSiYlk5JJyaRkUj9s2gwAX+fBFwAAAABJRU5ErkJg\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(255.0,189.0,0.0)    …  RGB{Float64}(222.0,134.0,0.0)\n",
              " RGB{Float64}(255.0,188.0,0.0)       RGB{Float64}(219.0,132.0,0.0)\n",
              " RGB{Float64}(255.0,189.0,0.0)       RGB{Float64}(221.0,133.0,0.0)\n",
              " RGB{Float64}(255.0,183.0,0.0)       RGB{Float64}(224.0,134.0,0.0)\n",
              " RGB{Float64}(255.0,184.0,0.0)       RGB{Float64}(218.0,131.0,0.0)\n",
              " RGB{Float64}(255.0,183.0,0.0)    …  RGB{Float64}(223.0,134.0,0.0)\n",
              " RGB{Float64}(255.0,177.0,0.0)       RGB{Float64}(225.0,136.0,0.0)\n",
              " RGB{Float64}(255.0,175.0,0.0)       RGB{Float64}(221.0,133.0,0.0)\n",
              " RGB{Float64}(255.0,177.0,0.0)       RGB{Float64}(219.0,132.0,0.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAWNJREFUeAHtwdGJHEEAxUA1KP+U2+yP5wLwngb8qrz3Mh2ZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJuVhSjIpL1OSSXmYkkxKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKXuDyOHzX5XHoyaTkBQ6Py3cd3kUmJS9w+T2Xx6Enk5LI5ePww+Hj8jj8S5ePw8flr8vHoSGTkve4PA7fcnkVmZSX0uWHw8fluw4fl5eQSXnoXUqHkkzKy//r0pNJyeFdDt9yeBxeQiYll7c4/J7LS8ik5PA/OryETEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTOoPiAwbAF9/Y3oAAAAASUVORK5CYII=",
            "text/html": [
              "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAWNJREFUeAHtwdGJHEEAxUA1KP+U2+yP5wLwngb8qrz3Mh2ZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJuVhSjIpL1OSSXmYkkxKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKJiWTkknJpGRSMimZlExKXuDyOHzX5XHoyaTkBQ6Py3cd3kUmJS9w+T2Xx6Enk5LI5ePww+Hj8jj8S5ePw8flr8vHoSGTkve4PA7fcnkVmZSX0uWHw8fluw4fl5eQSXnoXUqHkkzKy//r0pNJyeFdDt9yeBxeQiYll7c4/J7LS8ik5PA/OryETEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTEomJZOSScmkZFIyKZmUTOoPiAwbAF9/Y3oAAAAASUVORK5C\">"
            ],
            "text/plain": [
              "64×64 reinterpret(reshape, RGB{Float64}, ::Array{Float64, 3}) with eltype RGB{Float64}:\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)  …  RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " RGB{Float64}(153.0,226.0,249.0)     RGB{Float64}(153.0,226.0,249.0)\n",
              " ⋮                                ⋱  \n",
              " RGB{Float64}(63.0,0.0,255.0)     …  RGB{Float64}(44.0,0.0,217.0)\n",
              " RGB{Float64}(64.0,0.0,255.0)        RGB{Float64}(45.0,0.0,223.0)\n",
              " RGB{Float64}(61.0,0.0,255.0)        RGB{Float64}(44.0,0.0,217.0)\n",
              " RGB{Float64}(61.0,0.0,255.0)        RGB{Float64}(45.0,0.0,221.0)\n",
              " RGB{Float64}(61.0,0.0,255.0)        RGB{Float64}(45.0,0.0,223.0)\n",
              " RGB{Float64}(59.0,0.0,255.0)     …  RGB{Float64}(44.0,0.0,217.0)\n",
              " RGB{Float64}(59.0,0.0,255.0)        RGB{Float64}(45.0,0.0,222.0)\n",
              " RGB{Float64}(58.0,0.0,255.0)        RGB{Float64}(45.0,0.0,223.0)\n",
              " RGB{Float64}(57.0,0.0,255.0)        RGB{Float64}(45.0,0.0,223.0)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# show the images in the dataset\n",
        "function show_images(dataset)\n",
        "    random_idx = rand(1:100, 10)\n",
        "    for i in random_idx\n",
        "        img = dataset[i,:,:,:]\n",
        "        img = permutedims(img, [3,1,2])\n",
        "        img_float = float(img) # Convert image to float\n",
        "        display(Images.colorview(RGB, img_float))\n",
        "    end\n",
        "end\n",
        "\n",
        "# show the images in the dataset\n",
        "show_images(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PyObject <Figure size 3000x3000 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_images_grid(imgs_, num_images=25):\n",
        "  imgs_ = imgs_ / 255. # normalise values to range [0,1]\n",
        "  imgs_ = imgs_.astype(np.float32)\n",
        "  ncols = int(np.ceil(num_images**0.5))\n",
        "  nrows = int(np.ceil(num_images / ncols))\n",
        "  fig, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for ax_i, ax in enumerate(axes):\n",
        "    if ax_i < num_images:\n",
        "      ax.imshow(imgs_[ax_i], cmap='Greys_r', interpolation='nearest')\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "    else:\n",
        "      ax.axis('off')\n",
        "  return fig\n",
        "\"\"\"\n",
        "\n",
        "display(py\"show_images_grid\"(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "py\"\"\"\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def mask_image_random(n):\n",
        "    random_arrays = []\n",
        "    for i in range(n):\n",
        "        random_array = np.random.uniform(-1, 1, size=(64, 64, 3))\n",
        "        random_arrays.append(random_array)\n",
        "    return random_arrays\n",
        "\n",
        "def display(array1, array2, seed=None, title='Inputs and outputs of the model', n=10):\n",
        "    hopfield = False\n",
        "\n",
        "    dim = array1[0].shape[0]\n",
        "    # Displays ten random images from each one of the supplied arrays.\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        if hopfield is True:\n",
        "            plt.imshow(image1.reshape(dim, dim), cmap='binary', vmin=-1, vmax=1)\n",
        "        else:\n",
        "            plt.imshow(image1.reshape(dim, dim, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        if hopfield is True:\n",
        "            plt.imshow(image2.reshape(dim, dim), cmap='binary', vmin=-1, vmax=1)\n",
        "        else:\n",
        "            plt.imshow(image2.reshape(dim, dim, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    fig.suptitle(title)\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def preprocess(array):\n",
        "    # Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    array = array.astype(\"float64\") / 255.0\n",
        "    return array\n",
        "\n",
        "def prepare_data(dataset, display=False, noise_factor=0.6, labels=False,train=None, test=None):\n",
        "    # Normalize and reshape the data\n",
        "    train_data = preprocess(train)\n",
        "    test_data = preprocess(test)\n",
        "\n",
        "    # Create a copy of the data with added noise\n",
        "    noisy_train_data = noise(train_data, noise_factor=noise_factor)\n",
        "    noisy_test_data = noise(test_data, noise_factor=noise_factor)\n",
        "\n",
        "    # Display the train data and a version of it with added noise\n",
        "    if display is True:\n",
        "        display(train_data, noisy_train_data)\n",
        "\n",
        "    if labels is False:\n",
        "        return train_data, test_data, noisy_train_data, noisy_test_data\n",
        "\n",
        "def plot_history(history, decoding_history, titles=False):\n",
        "    recon_loss_values = history.history['reconstruction_loss']\n",
        "    decoding_acc_values = decoding_history.decoding_history\n",
        "    epochs = range(1, len(recon_loss_values) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(3, 3))\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.set_ylim(0, 1)\n",
        "    ax.set_ylabel(\"Reconstruction error\")\n",
        "    ax2.set_ylabel(\"Decoding accuracy\")\n",
        "\n",
        "    ax.plot(epochs, recon_loss_values, label='Reconstruction Error', color='red')\n",
        "    ax2.plot(epochs, decoding_acc_values, label='Decoding Accuracy', color='blue')\n",
        "\n",
        "    if titles is True:\n",
        "        lines, labels = ax.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax2.legend(lines + lines2, labels + labels2, loc=0)\n",
        "        plt.title('Reconstruction error and decoding accuracy over time')\n",
        "\n",
        "    ax.set_xlabel('Epoch')\n",
        "    plt.show()\n",
        "    return fig\n",
        "    \n",
        "def noise(array, noise_factor=0.4, seed=None, gaussian=False, replacement_val=0):\n",
        "    # Replace a fraction noise_factor of pixels with replacement_val or gaussian noise\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "    shape = array.shape\n",
        "    array = array.flatten()\n",
        "    indices = np.random.choice(np.arange(array.size), replace=False,\n",
        "                               size=int(array.size * noise_factor))\n",
        "    if gaussian is True:\n",
        "        array[indices] = np.random.normal(loc=0.5, scale=1.0, size=array[indices].shape)\n",
        "    else:\n",
        "        array[indices] = replacement_val\n",
        "    array = array.reshape(shape)\n",
        "    return np.clip(array, 0.0, 1.0)\n",
        "\n",
        "def check_generative_recall(vae, test_data, noise_level=0.1):\n",
        "    test_data = noise(test_data, noise_factor=noise_level)\n",
        "    latents = vae.encoder.predict(test_data)\n",
        "    predictions = vae.decoder.predict(latents[0])\n",
        "    fig = display(test_data, predictions, title='Inputs and outputs for VAE')\n",
        "    return fig\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hopfield network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "class ContinuousHopfield:\n",
        "    def __init__(self, pat_size, beta=100, do_normalization=True):\n",
        "        self.size = pat_size  # size of individual pattern\n",
        "        self.beta = beta\n",
        "        print(self.beta)\n",
        "        self.max_norm = np.sqrt(self.size)\n",
        "        if do_normalization:\n",
        "            self.softmax = self.softmax_normalized\n",
        "            self.energy = self.energy_normalized\n",
        "        else:\n",
        "            self.softmax = self.softmax_unnormalized\n",
        "            self.energy = self.energy_unnormalized\n",
        "\n",
        "        return\n",
        "\n",
        "    def learn(self, patterns):\n",
        "        # expects patterns as numpy arrays and stores them col-wise in pattern matrix \n",
        "        self.num_pat = len(patterns)\n",
        "        assert (all(type(x) is np.ndarray for x in patterns)), 'not all input patterns are numpy arrays'\n",
        "        assert (all(len(x.shape) == 2 for x in patterns)), 'not all input patterns have dimension 2'\n",
        "        assert (all(1 == x.shape[1] for x in patterns)), 'not all input patterns have shape (-1,1) '\n",
        "        self.patterns = np.array(patterns).squeeze(axis=-1).T  # save patterns col-wise\n",
        "        # without squeeze axis would result in problem with one pattern\n",
        "        # return -1*np.sum(np.exp([(self.patterns[:,ii].T @pattern)/self.max_norm for ii in range(self.patterns.shape[1])]))\n",
        "        self.M = max(np.linalg.norm(vec) for vec in patterns)  # maximal norm of actually stored patterns\n",
        "        return\n",
        "\n",
        "    def retrieve(self, partial_pattern, max_iter=np.inf, thresh=0.5):\n",
        "        # partial patterns have to be provided with None/0 at empty spots\n",
        "        if partial_pattern.size != self.size:\n",
        "            raise ValueError(\"Input pattern %r does not match state size: %d vs %d\"\n",
        "                             % (partial_pattern, len(partial_pattern), self.size))\n",
        "\n",
        "        if None in partial_pattern:\n",
        "            raise NotImplementedError(\"None elements not supported\")\n",
        "\n",
        "        assert type(partial_pattern) == np.ndarray, 'test pattern was not numpy array'\n",
        "        assert len(partial_pattern.shape) == 2 and 1 == partial_pattern.shape[\n",
        "            1], 'test pattern with shape %r is not a col-vector' % (partial_pattern.shape,)\n",
        "\n",
        "        pat_old = partial_pattern.copy()\n",
        "        iters = 0\n",
        "\n",
        "        while iters < max_iter:\n",
        "            pat_new = self.patterns @ self.softmax(self.beta * self.patterns.T @ pat_old)\n",
        "\n",
        "            if np.count_nonzero(pat_old != pat_new) <= thresh:  # converged\n",
        "                break\n",
        "            else:\n",
        "                pat_old = pat_new\n",
        "            iters += 1\n",
        "\n",
        "        return pat_new\n",
        "\n",
        "    def softmax_unnormalized(z):\n",
        "        return softmax(z)  # Scipy's softmax is numerically stable\n",
        "\n",
        "    def softmax_normalized(self, z):\n",
        "        return softmax(z / self.max_norm)\n",
        "\n",
        "    @staticmethod\n",
        "    def _lse(z, beta):\n",
        "        return 1 / beta * np.log(np.sum(np.exp(beta * z)))\n",
        "\n",
        "    def energy_unnormalized(self, pattern):\n",
        "        return -1 * self._lse(self.patterns.T @ pattern, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_normalized(self, pattern):\n",
        "        # normalize dot product of patterns by 1/sqrt(pattern_size)\n",
        "        return -1 * self._lse((self.patterns.T @ pattern) / self.max_norm, 1) + 0.5 * pattern.T @ pattern \\\n",
        "            + 1 / self.beta * np.log(self.num_pat) \\\n",
        "            + 0.5 * self.M ** 2\n",
        "\n",
        "    def energy_landscape(self):\n",
        "        for pat in product([1, -1], repeat=self.size):\n",
        "            pat = np.array(pat)\n",
        "            print(\"energy(%r)=%.3f\" % (pat, self.energy(pat)))\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "pat_size = 64*64*3\n",
        "net = py\"ContinuousHopfield\"(pat_size)\n",
        "net.learn(converted_train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape before reshaping: (64, 64, 3)\n",
            "shape after reshaping: (12288, 1)\n",
            "Sampling from modern Hopfield network."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_ind: 1\n",
            "test_ind: 2\n",
            "test_ind: 3\n",
            "test_ind: 4\n",
            "test_ind: 5\n",
            "test_ind: 6\n",
            "test_ind: 7\n",
            "test_ind: 8\n",
            "test_ind: 9\n",
            "test_ind: 10\n",
            "test_ind: 11\n",
            "test_ind: 12\n",
            "test_ind: 13\n",
            "test_ind: 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_ind: 15\n",
            "test_ind: 16\n",
            "test_ind: 17\n",
            "test_ind: 18\n",
            "test_ind: 19\n",
            "test_ind: 20\n",
            "test_ind: 21\n",
            "test_ind: 22\n",
            "test_ind: 23\n",
            "test_ind: 24\n",
            "test_ind: 25\n",
            "test_ind: 26\n",
            "test_ind: 27\n",
            "test_ind: 28\n",
            "test_ind: 29\n",
            "test_ind: 30\n",
            "test_ind: 31\n",
            "test_ind: 32\n",
            "test_ind: 33\n",
            "test_ind: 34\n",
            "test_ind: 35\n",
            "test_ind: 36\n",
            "test_ind: 37\n",
            "test_ind: 38\n",
            "test_ind: 39\n",
            "test_ind: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40\n",
            "test_ind: 41\n",
            "test_ind: 42\n",
            "test_ind: 43\n",
            "test_ind: 44\n",
            "test_ind: 45\n",
            "test_ind: 46\n",
            "test_ind: 47\n",
            "test_ind: 48\n",
            "test_ind: 49\n",
            "test_ind: 50\n",
            "test_ind: 51\n",
            "test_ind: 52\n",
            "test_ind: 53\n",
            "test_ind: 54\n",
            "test_ind: 55\n",
            "test_ind: 56\n",
            "test_ind: 57\n",
            "test_ind: 58\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_ind: 59\n",
            "test_ind: 60\n",
            "test_ind: 61\n",
            "test_ind: 62\n",
            "test_ind: 63\n",
            "test_ind: 64\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_ind: 65\n",
            "test_ind: 66\n",
            "test_ind: 67\n",
            "test_ind: 68\n",
            "test_ind: 69\n",
            "test_ind: 70\n",
            "test_ind: 71\n",
            "test_ind: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72\n",
            "test_ind: 73\n",
            "test_ind: 74\n",
            "test_ind: 75\n",
            "test_ind: 76\n",
            "test_ind: 77\n",
            "test_ind: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78\n",
            "test_ind: 79\n",
            "test_ind: 80\n",
            "test_ind: 81\n",
            "test_ind: 82\n",
            "test_ind: 83\n",
            "test_ind: 84\n",
            "test_ind: 85\n",
            "test_ind: 86\n",
            "test_ind: 87\n",
            "test_ind: 88\n",
            "test_ind: 89\n",
            "test_ind: 90\n",
            "test_ind: 91\n",
            "test_ind: 92\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PyObject <Figure size 2880x800 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_ind: 93\n",
            "test_ind: 94\n",
            "test_ind: 95\n",
            "test_ind: 96\n",
            "test_ind: 97\n",
            "test_ind: 98\n",
            "test_ind: 99\n",
            "test_ind: 100\n"
          ]
        }
      ],
      "source": [
        "n = 100\n",
        "np = py\"np\"\n",
        "images_masked_np = py\"mask_image_random\"(n)\n",
        "println(\"shape before reshaping: \", size(images_masked_np[1]))\n",
        "images_masked_np = [reshape(array, (64*64*3,1)) for array in images_masked_np]\n",
        "println(\"shape after reshaping: \", size(images_masked_np[1]))\n",
        "\n",
        "print(\"Sampling from modern Hopfield network.\")\n",
        "predictions = []\n",
        "tests = []\n",
        "for test_ind in 1:n\n",
        "    println(\"test_ind: \", test_ind)\n",
        "    test = images_masked_np[test_ind]\n",
        "    reconstructed = net.retrieve(test, max_iter=10)\n",
        "\n",
        "    reconstructed = reshape(reconstructed, (1, 64, 64, 3))\n",
        "    reconstructed = (reconstructed .+ 1) / 2\n",
        "    push!(predictions, reconstructed)\n",
        "    test = reshape(test, (1, 64, 64, 3))\n",
        "    test = (test .+ 1) / 2\n",
        "    push!(tests, test)\n",
        "end\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "tests = np.concatenate(tests, axis=0)\n",
        "\n",
        "display(py\"display\"(tests, predictions,n=10, title=\"Inputs and outputs of the Hopfield network\"))\n",
        "\n",
        "# rescale predictions back to interval [0, 1]\n",
        "# predictions = (predictions .+ 1) / 2\n",
        "\n",
        "# save the predictions\n",
        "save(\"predictions.jld\", \"predictions\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzAy1LrF4a9T"
      },
      "source": [
        "# Variational Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "py\"\"\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class VAE(keras.Model):\n",
        "\n",
        "    def __init__(self, encoder, decoder, kl_weighting=1, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.kl_weighting = kl_weighting\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = reconstruction_loss_fn(data, reconstruction)\n",
        "            kl_loss = kl_loss_fn(z_mean, z_log_var, self.kl_weighting)\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "def label_classifier(latents, labels, num=200):\n",
        "        np.random.seed(1)\n",
        "        x_train, x_test, y_train, y_test = train_test_split(latents[0], labels,\n",
        "                                                            test_size=0.5, random_state=1)\n",
        "        clf = make_pipeline(StandardScaler(), SVC())\n",
        "        clf.fit(x_train[0:num], y_train[0:num])\n",
        "        score = clf.score(x_test, y_test)\n",
        "        return score\n",
        "    \n",
        "class DecodingHistory(keras.callbacks.Callback):\n",
        "    \n",
        "        def __init__(self, dataset):\n",
        "            _, self.test_data, _, _, _, self.test_labels = prepare_data(dataset, labels=True)\n",
        "            self.decoding_history = []\n",
        "    \n",
        "        def on_epoch_begin(self, epoch, logs=None):\n",
        "            latents = self.model.encoder.predict(self.test_data)\n",
        "            score = label_classifier(latents, self.test_labels)\n",
        "            self.decoding_history.append(score)\n",
        "    \n",
        "    \n",
        "class Sampling(layers.Layer):\n",
        "        # Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
        "    \n",
        "        def call(self, inputs):\n",
        "            z_mean, z_log_var = inputs\n",
        "            batch = tf.shape(z_mean)[0]\n",
        "            dim = tf.shape(z_mean)[1]\n",
        "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "def encoder_network_large(input_shape, latent_dim=100):\n",
        "    input_img = layers.Input(shape=input_shape)\n",
        "    x = layers.Dropout(0.2, input_shape=input_shape)(input_img)\n",
        "    x = layers.Conv2D(32, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=(2, 2))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    z_mean = layers.Dense(latent_dim, name='mean')(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "    z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "    encoder = keras.Model(input_img, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "    return encoder, z_mean, z_log_var\n",
        "\n",
        "\n",
        "def decoder_network_large(latent_dim=100):\n",
        "    decoder_input = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(4096)(decoder_input)\n",
        "    x = layers.Reshape((4, 4, 256))(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(128, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(32, 3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D((2, 2), interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(3, 3, strides=1, padding='same', activation='sigmoid')(x)\n",
        "\n",
        "    decoder = keras.Model(decoder_input, x)\n",
        "    return decoder\n",
        "\n",
        "\n",
        "def build_encoder_decoder_large(latent_dim=5):\n",
        "    input_shape = (64, 64, 3)\n",
        "    encoder, z_mean, z_log_var = encoder_network_large(input_shape, latent_dim)\n",
        "    decoder = decoder_network_large(latent_dim)\n",
        "    return encoder, decoder\n",
        "\n",
        "def kl_loss_fn(z_mean, z_log_var, kl_weighting):\n",
        "    # take the sum across the n latent variables\n",
        "    # then take the mean across the batch\n",
        "    kl = K.mean(-0.5 * K.sum(1 + z_log_var \\\n",
        "                             - K.square(z_mean) \\\n",
        "                             - K.exp(z_log_var), axis=-1))\n",
        "    return kl_weighting * kl\n",
        "\n",
        "\n",
        "def reconstruction_loss_fn(x, t_decoded):\n",
        "    # mean_absolute_error() returns result of dim (n_in_batch, pixels)\n",
        "    # take the sum across the 64x64x3 pixels\n",
        "    # take the mean across the batch\n",
        "    data = x\n",
        "    reconstruction = t_decoded\n",
        "    # note that binary_crossentropy loss also gives good results\n",
        "    reconstruction_loss = tf.reduce_mean(tf.reduce_sum(\n",
        "        keras.losses.mean_absolute_error(data, reconstruction), axis=(1, 2)))\n",
        "    return reconstruction_loss\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting to train VAE.Input data shape:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 64, 64, 3)\n",
            "Training data shape:(100, 64, 64, 3)\n",
            "Test data shape:(10, 64, 64, 3)\n",
            "Epoch 1/10\n",
            "4/4 - 1s - loss: 1492.9392 - reconstruction_loss: 1467.7103 - kl_loss: 25.2287 - 861ms/epoch - 215ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 1338.1353 - reconstruction_loss: 1327.6011 - kl_loss: 10.5342 - 313ms/epoch - 78ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 1216.9929 - reconstruction_loss: 1211.8025 - kl_loss: 5.1904 - 284ms/epoch - 71ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 1226.2782 - reconstruction_loss: 1217.2552 - kl_loss: 9.0229 - 294ms/epoch - 73ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 1156.9904 - reconstruction_loss: 1142.6171 - kl_loss: 14.3733 - 284ms/epoch - 71ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 1116.0228 - reconstruction_loss: 1099.8311 - kl_loss: 16.1918 - 301ms/epoch - 75ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 1076.3705 - reconstruction_loss: 1065.9387 - kl_loss: 10.4318 - 301ms/epoch - 75ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 962.7591 - reconstruction_loss: 950.6633 - kl_loss: 12.0958 - 283ms/epoch - 71ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 862.6647 - reconstruction_loss: 839.4165 - kl_loss: 23.2481 - 281ms/epoch - 70ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 824.7113 - reconstruction_loss: 792.9341 - kl_loss: 31.7772 - 278ms/epoch - 70ms/step\n",
            "Recalling noisy images with the generative model:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PyObject <Figure size 2880x800 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r1/4 [======>.......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 0s 4ms/step\n",
            "\r1/4 [======>.......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 0s 13ms/step\n",
            "\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3-element Vector{Matrix{Float32}}:\n",
              " [169.46326 972.1902 … 962.7712 633.5663; -982.5036 938.0295 … 475.18542 363.89432; … ; -380.92938 621.7604 … 679.5986 292.03894; -2.1920683 752.2502 … 774.16266 358.33295]\n",
              " [-946.22437 -1404.4286 … -842.7272 -546.0293; -620.39075 -1011.1506 … -825.79395 -449.86426; … ; -801.9833 -1096.6251 … -729.99365 -431.71545; -809.90234 -1120.1991 … -663.2921 -464.95496]\n",
              " [169.46326 972.1902 … 962.7712 633.5663; -982.5036 938.0295 … 475.18542 363.89432; … ; -380.92938 621.7604 … 679.5986 292.03894; -2.1920683 752.2502 … 774.16266 358.33295]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "latent_dim = 5\n",
        "keras = py\"keras\"\n",
        "kl_weighting=1\n",
        "lr=0.001\n",
        "generative_epochs=10\n",
        "pickle = pyimport(\"pickle\")\n",
        "dataset = \"shapes3d\"\n",
        "print(\"Starting to train VAE.\")\n",
        "# build VAE with latent_dim latent variables\n",
        "encoder, decoder = py\"build_encoder_decoder_large\"(latent_dim=latent_dim)\n",
        "vae = py\"VAE\"(encoder, decoder, kl_weighting)\n",
        "# jit_compile set to False to run on MacOS\n",
        "opt = keras.optimizers.Adam(lr=lr, amsgrad=1, jit_compile=0)\n",
        "vae.compile(optimizer=opt)\n",
        "# decoding_history = py\"DecodingHistory\"(dataset)\n",
        "# history = keras.callbacks.History()\n",
        "# stop training if no loss improvement for three epochs\n",
        "# early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "println(\"Input data shape:\", size(predictions))\n",
        "println(\"Training data shape:\", size(train_data))\n",
        "println(\"Test data shape:\", size(test_data))\n",
        "\n",
        "# fit VAE\n",
        "vae.fit(predictions, epochs=generative_epochs, verbose=2, batch_size=32)\n",
        "\n",
        "vae.encoder.save_weights(\"model_weights/100_encoder.h5\")\n",
        "vae.decoder.save_weights(\"model_weights/100_decoder.h5\")\n",
        "\n",
        "# diplay(py\"plot_history\"(history, decoding_history))\n",
        "\n",
        "# pickle.dump(history.history['reconstruction_loss'], open(\"./outputs/history.pkl\", \"wb\"))\n",
        "# pickle.dump(decoding_history.decoding_history, open(\"./outputs/decoding.pkl\", \"wb\"))\n",
        "\n",
        "print(\"Recalling noisy images with the generative model:\")\n",
        "display(py\"check_generative_recall\"(vae, train_data))\n",
        "\n",
        "latents = vae.encoder.predict(test_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia 1.9.3",
      "language": "julia",
      "name": "julia-1.9"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
